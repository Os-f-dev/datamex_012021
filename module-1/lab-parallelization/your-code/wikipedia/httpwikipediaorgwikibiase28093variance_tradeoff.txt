b'<!DOCTYPE html>\n<html class="client-nojs" lang="en" dir="ltr">\n<head>\n<meta charset="UTF-8"/>\n<title>Bias\xe2\x80\x93variance tradeoff - Wikipedia</title>\n<script>document.documentElement.className="client-js";RLCONF={"wgBreakFrames":!1,"wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgRequestId":"YA@TogpAMNEAAIwYPaUAAAAV","wgCSPNonce":!1,"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":!1,"wgNamespaceNumber":0,"wgPageName":"Bias\xe2\x80\x93variance_tradeoff","wgTitle":"Bias\xe2\x80\x93variance tradeoff","wgCurRevisionId":996197234,"wgRevisionId":996197234,"wgArticleId":40678189,"wgIsArticle":!0,"wgIsRedirect":!1,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["Dilemmas","Model selection","Machine learning","Statistical classification"],"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgRelevantPageName":"Bias\xe2\x80\x93variance_tradeoff","wgRelevantArticleId":40678189,"wgIsProbablyEditable":!0,"wgRelevantPageIsProbablyEditable":!0,\n"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgMediaViewerOnClick":!0,"wgMediaViewerEnabledByDefault":!0,"wgPopupsReferencePreviews":!1,"wgPopupsConflictsWithNavPopupGadget":!1,"wgPopupsConflictsWithRefTooltipsGadget":!0,"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en"},"wgMFDisplayWikibaseDescriptions":{"search":!0,"nearby":!0,"watchlist":!0,"tagline":!1},"wgWMESchemaEditAttemptStepOversample":!1,"wgULSCurrentAutonym":"English","wgNoticeProject":"wikipedia","wgCentralAuthMobileDomain":!1,"wgEditSubmitButtonLabelPublish":!0,"wgULSPosition":"interlanguage","wgWikibaseItemId":"Q17003119"};RLSTATE={"ext.globalCssJs.user.styles":"ready","site.styles":"ready","noscript":"ready","user.styles":"ready","ext.globalCssJs.user":"ready","user":"ready","user.options":"loading","ext.cite.styles":"ready","ext.math.styles":"ready","skins.vector.styles.legacy":"ready","jquery.makeCollapsible.styles":"ready",\n"ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.uls.interlanguage":"ready","ext.wikimediaBadges":"ready","wikibase.client.init":"ready"};RLPAGEMODULES=["ext.cite.ux-enhancements","ext.math.scripts","site","mediawiki.page.ready","jquery.makeCollapsible","mediawiki.toc","skins.vector.legacy.js","ext.gadget.ReferenceTooltips","ext.gadget.charinsert","ext.gadget.extra-toolbar-buttons","ext.gadget.refToolbar","ext.gadget.switcher","ext.centralauth.centralautologin","mmv.head","mmv.bootstrap.autostart","ext.popups","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming","ext.uls.compactlinks","ext.uls.interface","ext.cx.eventlogging.campaigns","ext.centralNotice.geoIP","ext.centralNotice.startUp"];</script>\n<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.implement("user.options@1hzgi",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({"patrolToken":"+\\\\","watchToken":"+\\\\","csrfToken":"+\\\\"});\n});});</script>\n<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=ext.cite.styles%7Cext.math.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cjquery.makeCollapsible.styles%7Cskins.vector.styles.legacy%7Cwikibase.client.init&amp;only=styles&amp;skin=vector"/>\n<script async="" src="/w/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector"></script>\n<meta name="ResourceLoaderDynamicStyles" content=""/>\n<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector"/>\n<meta name="generator" content="MediaWiki 1.36.0-wmf.27"/>\n<meta name="referrer" content="origin"/>\n<meta name="referrer" content="origin-when-crossorigin"/>\n<meta name="referrer" content="origin-when-cross-origin"/>\n<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/thumb/6/64/Test_function_and_noisy_data.png/1200px-Test_function_and_noisy_data.png"/>\n<link rel="preconnect" href="//upload.wikimedia.org"/>\n<link rel="alternate" media="only screen and (max-width: 720px)" href="//en.m.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff"/>\n<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Bias%E2%80%93variance_tradeoff&amp;action=edit"/>\n<link rel="edit" title="Edit this page" href="/w/index.php?title=Bias%E2%80%93variance_tradeoff&amp;action=edit"/>\n<link rel="apple-touch-icon" href="/static/apple-touch/wikipedia.png"/>\n<link rel="shortcut icon" href="/static/favicon/wikipedia.ico"/>\n<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)"/>\n<link rel="EditURI" type="application/rsd+xml" href="//en.wikipedia.org/w/api.php?action=rsd"/>\n<link rel="license" href="//creativecommons.org/licenses/by-sa/3.0/"/>\n<link rel="canonical" href="https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff"/>\n<link rel="dns-prefetch" href="//login.wikimedia.org"/>\n<link rel="dns-prefetch" href="//meta.wikimedia.org" />\n</head>\n<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Bias\xe2\x80\x93variance_tradeoff rootpage-Bias\xe2\x80\x93variance_tradeoff skin-vector action-view skin-vector-legacy"><div id="mw-page-base" class="noprint"></div>\n<div id="mw-head-base" class="noprint"></div>\n<div id="content" class="mw-body" role="main">\n\t<a id="top"></a>\n\t<div id="siteNotice" class="mw-body-content"><!-- CentralNotice --></div>\n\t<div class="mw-indicators mw-body-content">\n\t</div>\n\t<h1 id="firstHeading" class="firstHeading" lang="en">Bias\xe2\x80\x93variance tradeoff</h1>\n\t<div id="bodyContent" class="mw-body-content">\n\t\t<div id="siteSub" class="noprint">From Wikipedia, the free encyclopedia</div>\n\t\t<div id="contentSub"></div>\n\t\t<div id="contentSub2"></div>\n\t\t\n\t\t<div id="jump-to-nav"></div>\n\t\t<a class="mw-jump-link" href="#mw-head">Jump to navigation</a>\n\t\t<a class="mw-jump-link" href="#searchInput">Jump to search</a>\n\t\t<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><div class="mw-parser-output"><style data-mw-deduplicate="TemplateStyles:r1002487873">.mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:#f8f9fa;border:1px solid #aaa;padding:0.2em;border-spacing:0.4em 0;text-align:center;line-height:1.4em;font-size:88%}.mw-parser-output .sidebar a{white-space:nowrap}.mw-parser-output .sidebar-wraplinks a{white-space:normal}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding-bottom:0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em 0}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding-top:0.2em;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding-top:0.4em;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.4em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding-top:0}.mw-parser-output .sidebar-image{padding:0.2em 0 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em}.mw-parser-output .sidebar-content{padding:0 0.1em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.4em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%}.mw-parser-output .sidebar-collapse .sidebar-navbar{padding-top:0.6em}.mw-parser-output .sidebar-collapse .mw-collapsible-toggle{margin-top:0.2em}.mw-parser-output .sidebar-list-title{text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}@media(max-width:720px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none;margin-left:0!important;margin-right:0!important}}</style><table class="sidebar sidebar-collapse vertical-navbox nomobile"><tbody><tr><td class="sidebar-pretitle">Part of a series on</td></tr><tr><th class="sidebar-title-with-pretitle"><a href="/wiki/Machine_learning" title="Machine learning">Machine learning</a><br />and<br /><a href="/wiki/Data_mining" title="Data mining">data mining</a></th></tr><tr><td class="sidebar-content">\n<div class="sidebar-list mw-collapsible mw-collapsed"><div class="sidebar-list-title">Problems</div><div class="sidebar-list-content mw-collapsible-content"><div class="hlist">\n<ul><li><a href="/wiki/Statistical_classification" title="Statistical classification">Classification</a></li>\n<li><a href="/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a></li>\n<li><a href="/wiki/Regression_analysis" title="Regression analysis">Regression</a></li>\n<li><a href="/wiki/Anomaly_detection" title="Anomaly detection">Anomaly detection</a></li>\n<li><a href="/wiki/Automated_machine_learning" title="Automated machine learning">AutoML</a></li>\n<li><a href="/wiki/Association_rule_learning" title="Association rule learning">Association rules</a></li>\n<li><a href="/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a></li>\n<li><a href="/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a></li>\n<li><a href="/wiki/Feature_engineering" title="Feature engineering">Feature engineering</a></li>\n<li><a href="/wiki/Feature_learning" title="Feature learning">Feature learning</a></li>\n<li><a href="/wiki/Online_machine_learning" title="Online machine learning">Online learning</a></li>\n<li><a href="/wiki/Semi-supervised_learning" title="Semi-supervised learning">Semi-supervised learning</a></li>\n<li><a href="/wiki/Unsupervised_learning" title="Unsupervised learning">Unsupervised learning</a></li>\n<li><a href="/wiki/Learning_to_rank" title="Learning to rank">Learning to rank</a></li>\n<li><a href="/wiki/Grammar_induction" title="Grammar induction">Grammar induction</a></li></ul>\n</div></div></div></td>\n</tr><tr><td class="sidebar-content">\n<div class="sidebar-list mw-collapsible mw-collapsed"><div class="sidebar-list-title"><div style="display:inline-block; padding:0.1em 0;line-height:1.2em;"><a href="/wiki/Supervised_learning" title="Supervised learning">Supervised learning</a><br /><style data-mw-deduplicate="TemplateStyles:r886047488">.mw-parser-output .nobold{font-weight:normal}</style><span class="nobold"><span style="font-size:85%;">(<b><a href="/wiki/Statistical_classification" title="Statistical classification">classification</a></b>&#160;&#8226;&#32;<b><a href="/wiki/Regression_analysis" title="Regression analysis">regression</a></b>)</span></span> </div></div><div class="sidebar-list-content mw-collapsible-content"><div class="hlist">\n<ul><li><a href="/wiki/Decision_tree_learning" title="Decision tree learning">Decision trees</a></li>\n<li><a href="/wiki/Ensemble_learning" title="Ensemble learning">Ensembles</a>\n<ul><li><a href="/wiki/Bootstrap_aggregating" title="Bootstrap aggregating">Bagging</a></li>\n<li><a href="/wiki/Boosting_(machine_learning)" title="Boosting (machine learning)">Boosting</a></li>\n<li><a href="/wiki/Random_forest" title="Random forest">Random forest</a></li></ul></li>\n<li><a href="/wiki/K-nearest_neighbors_algorithm" title="K-nearest neighbors algorithm"><i>k</i>-NN</a></li>\n<li><a href="/wiki/Linear_regression" title="Linear regression">Linear regression</a></li>\n<li><a href="/wiki/Naive_Bayes_classifier" title="Naive Bayes classifier">Naive Bayes</a></li>\n<li><a href="/wiki/Artificial_neural_network" title="Artificial neural network">Artificial neural networks</a></li>\n<li><a href="/wiki/Logistic_regression" title="Logistic regression">Logistic regression</a></li>\n<li><a href="/wiki/Perceptron" title="Perceptron">Perceptron</a></li>\n<li><a href="/wiki/Relevance_vector_machine" title="Relevance vector machine">Relevance vector machine (RVM)</a></li>\n<li><a href="/wiki/Support-vector_machine" title="Support-vector machine">Support vector machine (SVM)</a></li></ul>\n</div></div></div></td>\n</tr><tr><td class="sidebar-content">\n<div class="sidebar-list mw-collapsible mw-collapsed"><div class="sidebar-list-title"><a href="/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a></div><div class="sidebar-list-content mw-collapsible-content"><div class="hlist">\n<ul><li><a href="/wiki/BIRCH" title="BIRCH">BIRCH</a></li>\n<li><a href="/wiki/CURE_data_clustering_algorithm" class="mw-redirect" title="CURE data clustering algorithm">CURE</a></li>\n<li><a href="/wiki/Hierarchical_clustering" title="Hierarchical clustering">Hierarchical</a></li>\n<li><a href="/wiki/K-means_clustering" title="K-means clustering"><i>k</i>-means</a></li>\n<li><a href="/wiki/Expectation%E2%80%93maximization_algorithm" title="Expectation\xe2\x80\x93maximization algorithm">Expectation\xe2\x80\x93maximization (EM)</a></li>\n<li><br /><a href="/wiki/DBSCAN" title="DBSCAN">DBSCAN</a></li>\n<li><a href="/wiki/OPTICS_algorithm" title="OPTICS algorithm">OPTICS</a></li>\n<li><a href="/wiki/Mean-shift" class="mw-redirect" title="Mean-shift">Mean-shift</a></li></ul>\n</div></div></div></td>\n</tr><tr><td class="sidebar-content">\n<div class="sidebar-list mw-collapsible mw-collapsed"><div class="sidebar-list-title"><a href="/wiki/Dimensionality_reduction" title="Dimensionality reduction">Dimensionality reduction</a></div><div class="sidebar-list-content mw-collapsible-content"><div class="hlist">\n<ul><li><a href="/wiki/Factor_analysis" title="Factor analysis">Factor analysis</a></li>\n<li><a href="/wiki/Canonical_correlation" title="Canonical correlation">CCA</a></li>\n<li><a href="/wiki/Independent_component_analysis" title="Independent component analysis">ICA</a></li>\n<li><a href="/wiki/Linear_discriminant_analysis" title="Linear discriminant analysis">LDA</a></li>\n<li><a href="/wiki/Non-negative_matrix_factorization" title="Non-negative matrix factorization">NMF</a></li>\n<li><a href="/wiki/Principal_component_analysis" title="Principal component analysis">PCA</a></li>\n<li><a href="/wiki/Proper_generalized_decomposition" title="Proper generalized decomposition">PGD</a></li>\n<li><a href="/wiki/T-distributed_stochastic_neighbor_embedding" title="T-distributed stochastic neighbor embedding">t-SNE</a></li></ul>\n</div></div></div></td>\n</tr><tr><td class="sidebar-content">\n<div class="sidebar-list mw-collapsible mw-collapsed"><div class="sidebar-list-title"><a href="/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a></div><div class="sidebar-list-content mw-collapsible-content"><div class="hlist">\n<ul><li><a href="/wiki/Graphical_model" title="Graphical model">Graphical models</a>\n<ul><li><a href="/wiki/Bayesian_network" title="Bayesian network">Bayes net</a></li>\n<li><a href="/wiki/Conditional_random_field" title="Conditional random field">Conditional random field</a></li>\n<li><a href="/wiki/Hidden_Markov_model" title="Hidden Markov model">Hidden Markov</a></li></ul></li></ul>\n</div></div></div></td>\n</tr><tr><td class="sidebar-content">\n<div class="sidebar-list mw-collapsible mw-collapsed"><div class="sidebar-list-title"><a href="/wiki/Anomaly_detection" title="Anomaly detection">Anomaly detection</a></div><div class="sidebar-list-content mw-collapsible-content"><div class="hlist">\n<ul><li><a href="/wiki/K-nearest_neighbors_classification" class="mw-redirect" title="K-nearest neighbors classification"><i>k</i>-NN</a></li>\n<li><a href="/wiki/Local_outlier_factor" title="Local outlier factor">Local outlier factor</a></li></ul>\n</div></div></div></td>\n</tr><tr><td class="sidebar-content">\n<div class="sidebar-list mw-collapsible mw-collapsed"><div class="sidebar-list-title"><a href="/wiki/Artificial_neural_network" title="Artificial neural network">Artificial neural network</a></div><div class="sidebar-list-content mw-collapsible-content"><div class="hlist">\n<ul><li><a href="/wiki/Autoencoder" title="Autoencoder">Autoencoder</a></li>\n<li><a href="/wiki/Deep_learning" title="Deep learning">Deep learning</a></li>\n<li><a href="/wiki/DeepDream" title="DeepDream">DeepDream</a></li>\n<li><a href="/wiki/Multilayer_perceptron" title="Multilayer perceptron">Multilayer perceptron</a></li>\n<li><a href="/wiki/Recurrent_neural_network" title="Recurrent neural network">RNN</a>\n<ul><li><a href="/wiki/Long_short-term_memory" title="Long short-term memory">LSTM</a></li>\n<li><a href="/wiki/Gated_recurrent_unit" title="Gated recurrent unit">GRU</a></li>\n<li><a href="/wiki/Echo_state_network" title="Echo state network">ESN</a></li></ul></li>\n<li><a href="/wiki/Restricted_Boltzmann_machine" title="Restricted Boltzmann machine">Restricted Boltzmann machine</a></li>\n<li><a href="/wiki/Generative_adversarial_network" title="Generative adversarial network">GAN</a></li>\n<li><a href="/wiki/Self-organizing_map" title="Self-organizing map">SOM</a></li>\n<li><a href="/wiki/Convolutional_neural_network" title="Convolutional neural network">Convolutional neural network</a>\n<ul><li><a href="/wiki/U-Net" title="U-Net">U-Net</a></li></ul></li>\n<li><a href="/wiki/Transformer_(machine_learning_model)" title="Transformer (machine learning model)">Transformer</a></li>\n<li><a href="/wiki/Spiking_neural_network" title="Spiking neural network">Spiking neural network</a></li></ul>\n</div></div></div></td>\n</tr><tr><td class="sidebar-content">\n<div class="sidebar-list mw-collapsible mw-collapsed"><div class="sidebar-list-title"><a href="/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a></div><div class="sidebar-list-content mw-collapsible-content"><div class="hlist">\n<ul><li><a href="/wiki/Q-learning" title="Q-learning">Q-learning</a></li>\n<li><a href="/wiki/State%E2%80%93action%E2%80%93reward%E2%80%93state%E2%80%93action" title="State\xe2\x80\x93action\xe2\x80\x93reward\xe2\x80\x93state\xe2\x80\x93action">SARSA</a></li>\n<li><a href="/wiki/Temporal_difference_learning" title="Temporal difference learning">Temporal difference (TD)</a></li></ul>\n</div></div></div></td>\n</tr><tr><td class="sidebar-content">\n<div class="sidebar-list mw-collapsible mw-collapsed"><div class="sidebar-list-title">Theory</div><div class="sidebar-list-content mw-collapsible-content"><div class="hlist">\n<ul><li><a class="mw-selflink selflink">Bias\xe2\x80\x93variance tradeoff</a></li>\n<li><a href="/wiki/Computational_learning_theory" title="Computational learning theory">Computational learning theory</a></li>\n<li><a href="/wiki/Empirical_risk_minimization" title="Empirical risk minimization">Empirical risk minimization</a></li>\n<li><a href="/wiki/Occam_learning" title="Occam learning">Occam learning</a></li>\n<li><a href="/wiki/Probably_approximately_correct_learning" title="Probably approximately correct learning">PAC learning</a></li>\n<li><a href="/wiki/Statistical_learning_theory" title="Statistical learning theory">Statistical learning</a></li>\n<li><a href="/wiki/Vapnik%E2%80%93Chervonenkis_theory" title="Vapnik\xe2\x80\x93Chervonenkis theory">VC theory</a></li></ul>\n</div></div></div></td>\n</tr><tr><td class="sidebar-content">\n<div class="sidebar-list mw-collapsible mw-collapsed"><div class="sidebar-list-title">Machine-learning venues</div><div class="sidebar-list-content mw-collapsible-content"><div class="hlist">\n<ul><li><a href="/wiki/Conference_on_Neural_Information_Processing_Systems" title="Conference on Neural Information Processing Systems">NeurIPS</a></li>\n<li><a href="/wiki/International_Conference_on_Machine_Learning" title="International Conference on Machine Learning">ICML</a></li>\n<li><a href="/wiki/Machine_Learning_(journal)" title="Machine Learning (journal)">ML</a></li>\n<li><a href="/wiki/Journal_of_Machine_Learning_Research" title="Journal of Machine Learning Research">JMLR</a></li>\n<li><a rel="nofollow" class="external text" href="https://arxiv.org/list/cs.LG/recent">ArXiv:cs.LG</a></li></ul>\n</div></div></div></td>\n</tr><tr><td class="sidebar-content">\n<div class="sidebar-list mw-collapsible mw-collapsed"><div class="sidebar-list-title"><a href="/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary of artificial intelligence</a></div><div class="sidebar-list-content mw-collapsible-content"><div class="hlist">\n<ul><li><a href="/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary of artificial intelligence</a></li></ul>\n</div></div></div></td>\n</tr><tr><td class="sidebar-content">\n<div class="sidebar-list mw-collapsible mw-collapsed"><div class="sidebar-list-title">Related articles</div><div class="sidebar-list-content mw-collapsible-content"><div class="hlist">\n<ul><li><a href="/wiki/List_of_datasets_for_machine-learning_research" title="List of datasets for machine-learning research">List of datasets for machine-learning research</a></li>\n<li><a href="/wiki/Outline_of_machine_learning" title="Outline of machine learning">Outline of machine learning</a></li></ul>\n</div></div></div></td>\n</tr><tr><td class="sidebar-navbar"><style data-mw-deduplicate="TemplateStyles:r992953826">.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}.mw-parser-output .infobox .navbar{font-size:100%}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}</style><div class="navbar plainlinks hlist navbar-mini"><ul><li class="nv-view"><a href="/wiki/Template:Machine_learning_bar" title="Template:Machine learning bar"><abbr title="View this template">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Machine_learning_bar" title="Template talk:Machine learning bar"><abbr title="Discuss this template">t</abbr></a></li><li class="nv-edit"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Template:Machine_learning_bar&amp;action=edit"><abbr title="Edit this template">e</abbr></a></li></ul></div></td></tr></tbody></table>\n<style data-mw-deduplicate="TemplateStyles:r978413945/mw-parser-output/.tmulti">.mw-parser-output .tmulti .thumbinner{display:flex;flex-direction:column}.mw-parser-output .tmulti .trow{display:flex;flex-direction:row;clear:left;flex-wrap:wrap;width:100%;box-sizing:border-box}.mw-parser-output .tmulti .tsingle{margin:1px;float:left}.mw-parser-output .tmulti .theader{clear:both;font-weight:bold;text-align:center;align-self:center;background-color:transparent;width:100%}.mw-parser-output .tmulti .thumbcaption{background-color:transparent}.mw-parser-output .tmulti .text-align-left{text-align:left}.mw-parser-output .tmulti .text-align-right{text-align:right}.mw-parser-output .tmulti .text-align-center{text-align:center}@media all and (max-width:720px){.mw-parser-output .tmulti .thumbinner{width:100%!important;box-sizing:border-box;max-width:none!important;align-items:center}.mw-parser-output .tmulti .trow{justify-content:center}.mw-parser-output .tmulti .tsingle{float:none!important;max-width:100%!important;box-sizing:border-box;text-align:center}.mw-parser-output .tmulti .tsingle .thumbcaption{text-align:left}.mw-parser-output .tmulti .trow>.thumbcaption{text-align:center}}</style><div class="thumb tmulti tright"><div class="thumbinner" style="width:204px;max-width:204px"><div class="trow"><div class="tsingle" style="width:202px;max-width:202px"><div class="thumbimage"><a href="/wiki/File:Test_function_and_noisy_data.png" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/6/64/Test_function_and_noisy_data.png/200px-Test_function_and_noisy_data.png" decoding="async" width="200" height="150" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/6/64/Test_function_and_noisy_data.png/300px-Test_function_and_noisy_data.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/64/Test_function_and_noisy_data.png/400px-Test_function_and_noisy_data.png 2x" data-file-width="1201" data-file-height="901" /></a></div><div class="thumbcaption">Function and noisy data.</div></div></div><div class="trow"><div class="tsingle" style="width:202px;max-width:202px"><div class="thumbimage"><a href="/wiki/File:Radial_basis_function_fit,_spread%3D5.png" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/9/91/Radial_basis_function_fit%2C_spread%3D5.png/200px-Radial_basis_function_fit%2C_spread%3D5.png" decoding="async" width="200" height="150" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/9/91/Radial_basis_function_fit%2C_spread%3D5.png/300px-Radial_basis_function_fit%2C_spread%3D5.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/9/91/Radial_basis_function_fit%2C_spread%3D5.png/400px-Radial_basis_function_fit%2C_spread%3D5.png 2x" data-file-width="1201" data-file-height="901" /></a></div><div class="thumbcaption">spread=5</div></div></div><div class="trow"><div class="tsingle" style="width:202px;max-width:202px"><div class="thumbimage"><a href="/wiki/File:Radial_basis_function_fit,_spread%3D1.png" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/6/63/Radial_basis_function_fit%2C_spread%3D1.png/200px-Radial_basis_function_fit%2C_spread%3D1.png" decoding="async" width="200" height="150" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/6/63/Radial_basis_function_fit%2C_spread%3D1.png/300px-Radial_basis_function_fit%2C_spread%3D1.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/6/63/Radial_basis_function_fit%2C_spread%3D1.png/400px-Radial_basis_function_fit%2C_spread%3D1.png 2x" data-file-width="1201" data-file-height="901" /></a></div><div class="thumbcaption">spread=1</div></div></div><div class="trow"><div class="tsingle" style="width:202px;max-width:202px"><div class="thumbimage"><a href="/wiki/File:Radial_basis_function_fit,_spread%3D0.1.png" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Radial_basis_function_fit%2C_spread%3D0.1.png/200px-Radial_basis_function_fit%2C_spread%3D0.1.png" decoding="async" width="200" height="150" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Radial_basis_function_fit%2C_spread%3D0.1.png/300px-Radial_basis_function_fit%2C_spread%3D0.1.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Radial_basis_function_fit%2C_spread%3D0.1.png/400px-Radial_basis_function_fit%2C_spread%3D0.1.png 2x" data-file-width="1201" data-file-height="901" /></a></div><div class="thumbcaption">spread=0.1</div></div></div><div class="trow" style="display:flex"><div class="thumbcaption">A function (red) is approximated using <a href="/wiki/Radial_basis_functions" class="mw-redirect" title="Radial basis functions">radial basis functions</a> (blue). Several trials are shown in each graph. For each trial, a few noisy data points are provided as a training set (top). For a wide spread (image 2) the bias is high: the RBFs cannot fully approximate the function (especially the central dip), but the variance between different trials is low. As spread decreases (image 3 and 4) the bias decreases: the blue curves more closely approximate the red. However, depending on the noise in different trials the variance between trials increases. In the lowermost image the approximated values for x=0 varies wildly depending on where the data points were located.</div></div></div></div>\n<p>In <a href="/wiki/Statistics" title="Statistics">statistics</a> and <a href="/wiki/Machine_learning" title="Machine learning">machine learning</a>, the <b>bias\xe2\x80\x93variance tradeoff</b> is the property of a model that the <a href="/wiki/Variance" title="Variance">variance</a> of the parameter estimates across <a href="/wiki/Sample_(statistics)" title="Sample (statistics)">samples</a> can be reduced by increasing the <a href="/wiki/Bias_of_an_estimator" title="Bias of an estimator">bias</a> in the <a href="/wiki/Estimation_theory" title="Estimation theory">estimated</a> <a href="/wiki/Statistical_parameter" title="Statistical parameter">parameters</a>.\nThe <b>bias\xe2\x80\x93variance dilemma</b> or <b>bias\xe2\x80\x93variance problem</b> is the conflict in trying to simultaneously minimize these two sources of <a href="/wiki/Errors_and_residuals_in_statistics" class="mw-redirect" title="Errors and residuals in statistics">error</a> that prevent <a href="/wiki/Supervised_learning" title="Supervised learning">supervised learning</a> algorithms from generalizing beyond their <a href="/wiki/Training_set" class="mw-redirect" title="Training set">training set</a>:<sup id="cite_ref-1" class="reference"><a href="#cite_note-1">&#91;1&#93;</a></sup><sup id="cite_ref-2" class="reference"><a href="#cite_note-2">&#91;2&#93;</a></sup>\n</p>\n<ul><li>The <a href="/wiki/Bias_of_an_estimator" title="Bias of an estimator"><i>bias error</i></a> is an error from erroneous assumptions in the learning <a href="/wiki/Algorithm" title="Algorithm">algorithm</a>. High bias can cause an algorithm to miss the relevant relations between features and target outputs (underfitting).</li>\n<li>The <i><a href="/wiki/Variance" title="Variance">variance</a></i> is an error from sensitivity to small fluctuations in the training set. High variance can cause an algorithm to model the random <a href="/wiki/Noise_(signal_processing)" title="Noise (signal processing)">noise</a> in the training data, rather than the intended outputs (<a href="/wiki/Overfitting" title="Overfitting">overfitting</a>).</li></ul>\n<p>This trade-off is universal: It has been shown that a model that is asymptotically unbiased must have unbounded variance.<sup id="cite_ref-3" class="reference"><a href="#cite_note-3">&#91;3&#93;</a></sup>\n</p><p>The <b>bias\xe2\x80\x93variance decomposition</b> is a way of analyzing a learning algorithm\'s <a href="/wiki/Expected_value" title="Expected value">expected</a> <a href="/wiki/Generalization_error" title="Generalization error">generalization error</a> with respect to a particular problem as a sum of three terms, the bias, variance, and a quantity called the <i>irreducible error</i>, resulting from noise in the problem itself.\n</p>\n<div id="toc" class="toc" role="navigation" aria-labelledby="mw-toc-heading"><input type="checkbox" role="button" id="toctogglecheckbox" class="toctogglecheckbox" style="display:none" /><div class="toctitle" lang="en" dir="ltr"><h2 id="mw-toc-heading">Contents</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div>\n<ul>\n<li class="toclevel-1 tocsection-1"><a href="#Motivation"><span class="tocnumber">1</span> <span class="toctext">Motivation</span></a></li>\n<li class="toclevel-1 tocsection-2"><a href="#Bias\xe2\x80\x93variance_decomposition_of_mean_squared_error"><span class="tocnumber">2</span> <span class="toctext">Bias\xe2\x80\x93variance decomposition of mean squared error</span></a>\n<ul>\n<li class="toclevel-2 tocsection-3"><a href="#Derivation"><span class="tocnumber">2.1</span> <span class="toctext">Derivation</span></a></li>\n</ul>\n</li>\n<li class="toclevel-1 tocsection-4"><a href="#Approaches"><span class="tocnumber">3</span> <span class="toctext">Approaches</span></a>\n<ul>\n<li class="toclevel-2 tocsection-5"><a href="#k-nearest_neighbors"><span class="tocnumber">3.1</span> <span class="toctext"><i>k</i>-nearest neighbors</span></a></li>\n</ul>\n</li>\n<li class="toclevel-1 tocsection-6"><a href="#Applications"><span class="tocnumber">4</span> <span class="toctext">Applications</span></a>\n<ul>\n<li class="toclevel-2 tocsection-7"><a href="#In_regression"><span class="tocnumber">4.1</span> <span class="toctext">In regression</span></a></li>\n<li class="toclevel-2 tocsection-8"><a href="#In_classification"><span class="tocnumber">4.2</span> <span class="toctext">In classification</span></a></li>\n<li class="toclevel-2 tocsection-9"><a href="#In_reinforcement_learning"><span class="tocnumber">4.3</span> <span class="toctext">In reinforcement learning</span></a></li>\n<li class="toclevel-2 tocsection-10"><a href="#In_human_learning"><span class="tocnumber">4.4</span> <span class="toctext">In human learning</span></a></li>\n</ul>\n</li>\n<li class="toclevel-1 tocsection-11"><a href="#See_also"><span class="tocnumber">5</span> <span class="toctext">See also</span></a></li>\n<li class="toclevel-1 tocsection-12"><a href="#References"><span class="tocnumber">6</span> <span class="toctext">References</span></a></li>\n</ul>\n</div>\n\n<h2><span class="mw-headline" id="Motivation">Motivation</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Bias%E2%80%93variance_tradeoff&amp;action=edit&amp;section=1" title="Edit section: Motivation">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<p>The bias-variance tradeoff is a central problem in supervised learning. Ideally, one wants to <a href="/wiki/Model_selection" title="Model selection">choose a model</a> that both accurately captures the regularities in its training data, but also <a href="/wiki/Generalization" title="Generalization">generalizes</a> well to unseen data. Unfortunately, it is typically impossible to do both simultaneously. High-variance learning methods may be able to represent their training set well but are at risk of overfitting to noisy or unrepresentative training data. In contrast, algorithms with high bias typically produce simpler models that don\'t tend to overfit but may <i>underfit</i> their training data, failing to capture important regularities.\n</p><p>It is an often made <a href="/wiki/Affirming_the_consequent" title="Affirming the consequent">fallacy</a><sup id="cite_ref-nealThesis2019_4-0" class="reference"><a href="#cite_note-nealThesis2019-4">&#91;4&#93;</a></sup><sup id="cite_ref-neal2018_5-0" class="reference"><a href="#cite_note-neal2018-5">&#91;5&#93;</a></sup> to assume that complex models must have high variance; High variance models are \'complex\' in some sense, but the reverse needs not be true.\nIn addition one has to be careful how to define complexity: In particular, the number of parameters used to describe the model is a poor measure of complexity. This is illustrated by an example adapted from:<sup id="cite_ref-6" class="reference"><a href="#cite_note-6">&#91;6&#93;</a></sup> The model <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle f_{a,b}(x)=a\\sin(bx)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>f</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>a</mi>\n            <mo>,</mo>\n            <mi>b</mi>\n          </mrow>\n        </msub>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo stretchy="false">)</mo>\n        <mo>=</mo>\n        <mi>a</mi>\n        <mi>sin</mi>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mo stretchy="false">(</mo>\n        <mi>b</mi>\n        <mi>x</mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle f_{a,b}(x)=a\\sin(bx)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/14ef53fa675be7cb7d9171699294ad22879fe078" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:18.25ex; height:3.009ex;" alt="{\\displaystyle f_{a,b}(x)=a\\sin(bx)}"/></span> has only two parameters (<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle a,b}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>a</mi>\n        <mo>,</mo>\n        <mi>b</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle a,b}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/181523deba732fda302fd176275a0739121d3bc8" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:3.261ex; height:2.509ex;" alt="a,b"/></span>) but it can interpolate any number of points by oscillating with a high enough frequency, resulting in both a high bias and high variance.\n</p><p>Intuitively, bias is reduced by using only local information, whereas variance can only be reduced by averaging over multiple observations, which inherently means using information from a larger region. For an enlightening example, see the section on k-nearest neighbors or the figure on the right.\nTo balance how much information is used from neighboring observations, a model can be <a href="/wiki/Smoothing" title="Smoothing">smoothed</a> via explicit <a href="/wiki/Regularization_(mathematics)" title="Regularization (mathematics)">regularization</a>, such as <a href="/wiki/Shrinkage_(statistics)" title="Shrinkage (statistics)">shrinkage</a>.\n</p>\n<h2><span id="Bias.E2.80.93variance_decomposition_of_mean_squared_error"></span><span class="mw-headline" id="Bias\xe2\x80\x93variance_decomposition_of_mean_squared_error">Bias\xe2\x80\x93variance decomposition of mean squared error</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Bias%E2%80%93variance_tradeoff&amp;action=edit&amp;section=2" title="Edit section: Bias\xe2\x80\x93variance decomposition of mean squared error">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/Mean_squared_error" title="Mean squared error">Mean squared error</a></div>\n<p>Suppose that we have a training set consisting of a set of points <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle x_{1},\\dots ,x_{n}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>x</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>1</mn>\n          </mrow>\n        </msub>\n        <mo>,</mo>\n        <mo>&#x2026;<!-- \xe2\x80\xa6 --></mo>\n        <mo>,</mo>\n        <msub>\n          <mi>x</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>n</mi>\n          </mrow>\n        </msub>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle x_{1},\\dots ,x_{n}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e5afdbc2d248d8fa9ba2c4f5188d946a0537e753" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:10.11ex; height:2.009ex;" alt="x_{1},\\dots ,x_{n}"/></span> and real values <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle y_{i}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>y</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>i</mi>\n          </mrow>\n        </msub>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle y_{i}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/67d30d30b6c2dbe4d6f150d699de040937ecc95f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.939ex; height:2.009ex;" alt="y_{i}"/></span> associated with each point <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle x_{i}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>x</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>i</mi>\n          </mrow>\n        </msub>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle x_{i}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e87000dd6142b81d041896a30fe58f0c3acb2158" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:2.129ex; height:2.009ex;" alt="x_{i}"/></span>. We assume that there is a function with noise <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle y=f(x)+\\varepsilon }">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>y</mi>\n        <mo>=</mo>\n        <mi>f</mi>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo stretchy="false">)</mo>\n        <mo>+</mo>\n        <mi>&#x03B5;<!-- \xce\xb5 --></mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle y=f(x)+\\varepsilon }</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/93f385c9e8b0b5372dd00cfcaa57b1fe20bb812b" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:12.595ex; height:2.843ex;" alt="{\\displaystyle y=f(x)+\\varepsilon }"/></span>, where the noise, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\varepsilon }">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>&#x03B5;<!-- \xce\xb5 --></mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\varepsilon }</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a30c89172e5b88edbd45d3e2772c7f5e562e5173" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.083ex; height:1.676ex;" alt="\\varepsilon "/></span>, has zero mean and variance <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\sigma ^{2}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msup>\n          <mi>&#x03C3;<!-- \xcf\x83 --></mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>2</mn>\n          </mrow>\n        </msup>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\sigma ^{2}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/53a5c55e536acf250c1d3e0f754be5692b843ef5" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:2.385ex; height:2.676ex;" alt="\\sigma ^{2}"/></span>.\n</p><p>We want to find a function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle {\\hat {f}}(x;D)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>f</mi>\n              <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo>;</mo>\n        <mi>D</mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle {\\hat {f}}(x;D)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/104cc1ab5f9c97a82bdf05c6e5999d69b9db08a7" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:7.796ex; height:3.343ex;" alt="{\\displaystyle {\\hat {f}}(x;D)}"/></span>, that approximates the true function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle f(x)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>f</mi>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle f(x)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/202945cce41ecebb6f643f31d119c514bec7a074" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:4.418ex; height:2.843ex;" alt="f(x)"/></span> as well as possible, by means of some learning algorithm based on a training dataset (sample) <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle D=\\{(x_{1},y_{1})\\dots ,(x_{n},y_{n})\\}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>D</mi>\n        <mo>=</mo>\n        <mo fence="false" stretchy="false">{</mo>\n        <mo stretchy="false">(</mo>\n        <msub>\n          <mi>x</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>1</mn>\n          </mrow>\n        </msub>\n        <mo>,</mo>\n        <msub>\n          <mi>y</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>1</mn>\n          </mrow>\n        </msub>\n        <mo stretchy="false">)</mo>\n        <mo>&#x2026;<!-- \xe2\x80\xa6 --></mo>\n        <mo>,</mo>\n        <mo stretchy="false">(</mo>\n        <msub>\n          <mi>x</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>n</mi>\n          </mrow>\n        </msub>\n        <mo>,</mo>\n        <msub>\n          <mi>y</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>n</mi>\n          </mrow>\n        </msub>\n        <mo stretchy="false">)</mo>\n        <mo fence="false" stretchy="false">}</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle D=\\{(x_{1},y_{1})\\dots ,(x_{n},y_{n})\\}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/757190ec5d200f1ca40a0d23e32f090a12352b6d" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:27.049ex; height:2.843ex;" alt="{\\displaystyle D=\\{(x_{1},y_{1})\\dots ,(x_{n},y_{n})\\}}"/></span>. We make "as well as possible" precise by measuring the <a href="/wiki/Mean_squared_error" title="Mean squared error">mean squared error</a> between <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle y}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>y</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle y}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b8a6208ec717213d4317e666f1ae872e00620a0d" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.155ex; height:2.009ex;" alt="y"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle {\\hat {f}}(x;D)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>f</mi>\n              <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo>;</mo>\n        <mi>D</mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle {\\hat {f}}(x;D)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/104cc1ab5f9c97a82bdf05c6e5999d69b9db08a7" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:7.796ex; height:3.343ex;" alt="{\\displaystyle {\\hat {f}}(x;D)}"/></span>: we want <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle (y-{\\hat {f}}(x;D))^{2}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mo stretchy="false">(</mo>\n        <mi>y</mi>\n        <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>f</mi>\n              <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo>;</mo>\n        <mi>D</mi>\n        <mo stretchy="false">)</mo>\n        <msup>\n          <mo stretchy="false">)</mo>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>2</mn>\n          </mrow>\n        </msup>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle (y-{\\hat {f}}(x;D))^{2}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/fcff55548f0c80eb86405dd0e2e894b6d3734f1a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:14.656ex; height:3.343ex;" alt="{\\displaystyle (y-{\\hat {f}}(x;D))^{2}}"/></span> to be minimal, both for <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle x_{1},\\dots ,x_{n}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>x</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>1</mn>\n          </mrow>\n        </msub>\n        <mo>,</mo>\n        <mo>&#x2026;<!-- \xe2\x80\xa6 --></mo>\n        <mo>,</mo>\n        <msub>\n          <mi>x</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>n</mi>\n          </mrow>\n        </msub>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle x_{1},\\dots ,x_{n}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e5afdbc2d248d8fa9ba2c4f5188d946a0537e753" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:10.11ex; height:2.009ex;" alt="x_{1},\\dots ,x_{n}"/></span> <i>and for points outside of our sample</i>. Of course, we cannot hope to do so perfectly, since the <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle y_{i}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>y</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>i</mi>\n          </mrow>\n        </msub>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle y_{i}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/67d30d30b6c2dbe4d6f150d699de040937ecc95f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.939ex; height:2.009ex;" alt="y_{i}"/></span> contain noise <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\varepsilon }">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>&#x03B5;<!-- \xce\xb5 --></mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\varepsilon }</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a30c89172e5b88edbd45d3e2772c7f5e562e5173" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.083ex; height:1.676ex;" alt="\\varepsilon "/></span>; this means we must be prepared to accept an <i>irreducible error</i> in any function we come up with.\n</p><p>Finding an <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle {\\hat {f}}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>f</mi>\n              <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle {\\hat {f}}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/14ce989fd75da938ec6f95a0cdb71037b23a11cb" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.699ex; height:3.176ex;" alt="{\\hat {f}}"/></span> that generalizes to points outside of the training set can be done with any of the countless algorithms used for supervised learning. It turns out that whichever function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle {\\hat {f}}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>f</mi>\n              <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle {\\hat {f}}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/14ce989fd75da938ec6f95a0cdb71037b23a11cb" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.699ex; height:3.176ex;" alt="{\\hat {f}}"/></span> we select, we can decompose its <a href="/wiki/Expected_value" title="Expected value">expected</a> error on an unseen sample <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle x}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>x</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle x}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.33ex; height:1.676ex;" alt="x"/></span> as follows:<sup id="cite_ref-islr_7-0" class="reference"><a href="#cite_note-islr-7">&#91;7&#93;</a></sup><sup class="reference" style="white-space:nowrap;">:<span>34</span></sup><sup id="cite_ref-ESL_8-0" class="reference"><a href="#cite_note-ESL-8">&#91;8&#93;</a></sup><sup class="reference" style="white-space:nowrap;">:<span>223</span></sup>\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\operatorname {E} _{D}{\\Big [}{\\big (}y-{\\hat {f}}(x;D){\\big )}^{2}{\\Big ]}={\\Big (}\\operatorname {Bias} _{D}{\\big [}{\\hat {f}}(x;D){\\big ]}{\\Big )}^{2}+\\operatorname {Var} _{D}{\\big [}{\\hat {f}}(x;D){\\big ]}+\\sigma ^{2}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi mathvariant="normal">E</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>D</mi>\n          </mrow>\n        </msub>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mo maxsize="1.623em" minsize="1.623em">[</mo>\n          </mrow>\n        </mrow>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mo maxsize="1.2em" minsize="1.2em">(</mo>\n          </mrow>\n        </mrow>\n        <mi>y</mi>\n        <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>f</mi>\n              <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo>;</mo>\n        <mi>D</mi>\n        <mo stretchy="false">)</mo>\n        <msup>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mrow class="MJX-TeXAtom-ORD">\n              <mo maxsize="1.2em" minsize="1.2em">)</mo>\n            </mrow>\n          </mrow>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>2</mn>\n          </mrow>\n        </msup>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mo maxsize="1.623em" minsize="1.623em">]</mo>\n          </mrow>\n        </mrow>\n        <mo>=</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mo maxsize="1.623em" minsize="1.623em">(</mo>\n          </mrow>\n        </mrow>\n        <msub>\n          <mi>Bias</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>D</mi>\n          </mrow>\n        </msub>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mo maxsize="1.2em" minsize="1.2em">[</mo>\n          </mrow>\n        </mrow>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>f</mi>\n              <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo>;</mo>\n        <mi>D</mi>\n        <mo stretchy="false">)</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mo maxsize="1.2em" minsize="1.2em">]</mo>\n          </mrow>\n        </mrow>\n        <msup>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mrow class="MJX-TeXAtom-ORD">\n              <mo maxsize="1.623em" minsize="1.623em">)</mo>\n            </mrow>\n          </mrow>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>2</mn>\n          </mrow>\n        </msup>\n        <mo>+</mo>\n        <msub>\n          <mi>Var</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>D</mi>\n          </mrow>\n        </msub>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mo maxsize="1.2em" minsize="1.2em">[</mo>\n          </mrow>\n        </mrow>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>f</mi>\n              <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo>;</mo>\n        <mi>D</mi>\n        <mo stretchy="false">)</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mo maxsize="1.2em" minsize="1.2em">]</mo>\n          </mrow>\n        </mrow>\n        <mo>+</mo>\n        <msup>\n          <mi>&#x03C3;<!-- \xcf\x83 --></mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>2</mn>\n          </mrow>\n        </msup>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\operatorname {E} _{D}{\\Big [}{\\big (}y-{\\hat {f}}(x;D){\\big )}^{2}{\\Big ]}={\\Big (}\\operatorname {Bias} _{D}{\\big [}{\\hat {f}}(x;D){\\big ]}{\\Big )}^{2}+\\operatorname {Var} _{D}{\\big [}{\\hat {f}}(x;D){\\big ]}+\\sigma ^{2}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d5a2f3d7e452720a1f105dff963ad490221a4a80" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.838ex; width:67.734ex; height:5.176ex;" alt="{\\displaystyle \\operatorname {E} _{D}{\\Big [}{\\big (}y-{\\hat {f}}(x;D){\\big )}^{2}{\\Big ]}={\\Big (}\\operatorname {Bias} _{D}{\\big [}{\\hat {f}}(x;D){\\big ]}{\\Big )}^{2}+\\operatorname {Var} _{D}{\\big [}{\\hat {f}}(x;D){\\big ]}+\\sigma ^{2}}"/></span></dd></dl>\n<p>where\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\operatorname {Bias} _{D}{\\big [}{\\hat {f}}(x;D){\\big ]}=\\operatorname {E} _{D}{\\big [}{\\hat {f}}(x;D){\\big ]}-f(x)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>Bias</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>D</mi>\n          </mrow>\n        </msub>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mo maxsize="1.2em" minsize="1.2em">[</mo>\n          </mrow>\n        </mrow>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>f</mi>\n              <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo>;</mo>\n        <mi>D</mi>\n        <mo stretchy="false">)</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mo maxsize="1.2em" minsize="1.2em">]</mo>\n          </mrow>\n        </mrow>\n        <mo>=</mo>\n        <msub>\n          <mi mathvariant="normal">E</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>D</mi>\n          </mrow>\n        </msub>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mo maxsize="1.2em" minsize="1.2em">[</mo>\n          </mrow>\n        </mrow>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>f</mi>\n              <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo>;</mo>\n        <mi>D</mi>\n        <mo stretchy="false">)</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mo maxsize="1.2em" minsize="1.2em">]</mo>\n          </mrow>\n        </mrow>\n        <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n        <mi>f</mi>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\operatorname {Bias} _{D}{\\big [}{\\hat {f}}(x;D){\\big ]}=\\operatorname {E} _{D}{\\big [}{\\hat {f}}(x;D){\\big ]}-f(x)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a0013efa4f5587aa74b8c5511bf4b5864c3f5c56" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:39.742ex; height:3.509ex;" alt="{\\displaystyle \\operatorname {Bias} _{D}{\\big [}{\\hat {f}}(x;D){\\big ]}=\\operatorname {E} _{D}{\\big [}{\\hat {f}}(x;D){\\big ]}-f(x)}"/></span></dd></dl>\n<p>and\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\operatorname {Var} _{D}{\\big [}{\\hat {f}}(x;D){\\big ]}=\\operatorname {E} _{D}[{\\big (}\\operatorname {E} _{D}[{\\hat {f}}(x;D)]-{\\hat {f}}(x;D){\\big )}^{2}].}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>Var</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>D</mi>\n          </mrow>\n        </msub>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mo maxsize="1.2em" minsize="1.2em">[</mo>\n          </mrow>\n        </mrow>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>f</mi>\n              <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo>;</mo>\n        <mi>D</mi>\n        <mo stretchy="false">)</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mo maxsize="1.2em" minsize="1.2em">]</mo>\n          </mrow>\n        </mrow>\n        <mo>=</mo>\n        <msub>\n          <mi mathvariant="normal">E</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>D</mi>\n          </mrow>\n        </msub>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mo stretchy="false">[</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mo maxsize="1.2em" minsize="1.2em">(</mo>\n          </mrow>\n        </mrow>\n        <msub>\n          <mi mathvariant="normal">E</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>D</mi>\n          </mrow>\n        </msub>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mo stretchy="false">[</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>f</mi>\n              <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo>;</mo>\n        <mi>D</mi>\n        <mo stretchy="false">)</mo>\n        <mo stretchy="false">]</mo>\n        <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>f</mi>\n              <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo>;</mo>\n        <mi>D</mi>\n        <mo stretchy="false">)</mo>\n        <msup>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mrow class="MJX-TeXAtom-ORD">\n              <mo maxsize="1.2em" minsize="1.2em">)</mo>\n            </mrow>\n          </mrow>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>2</mn>\n          </mrow>\n        </msup>\n        <mo stretchy="false">]</mo>\n        <mo>.</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\operatorname {Var} _{D}{\\big [}{\\hat {f}}(x;D){\\big ]}=\\operatorname {E} _{D}[{\\big (}\\operatorname {E} _{D}[{\\hat {f}}(x;D)]-{\\hat {f}}(x;D){\\big )}^{2}].}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/00217394951130843b79dfb8bbd6e2374515bbbf" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:50.221ex; height:3.676ex;" alt="{\\displaystyle \\operatorname {Var} _{D}{\\big [}{\\hat {f}}(x;D){\\big ]}=\\operatorname {E} _{D}[{\\big (}\\operatorname {E} _{D}[{\\hat {f}}(x;D)]-{\\hat {f}}(x;D){\\big )}^{2}].}"/></span></dd></dl>\n<p>The expectation ranges over different choices of the training set <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle D=\\{(x_{1},y_{1})\\dots ,(x_{n},y_{n})\\}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>D</mi>\n        <mo>=</mo>\n        <mo fence="false" stretchy="false">{</mo>\n        <mo stretchy="false">(</mo>\n        <msub>\n          <mi>x</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>1</mn>\n          </mrow>\n        </msub>\n        <mo>,</mo>\n        <msub>\n          <mi>y</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>1</mn>\n          </mrow>\n        </msub>\n        <mo stretchy="false">)</mo>\n        <mo>&#x2026;<!-- \xe2\x80\xa6 --></mo>\n        <mo>,</mo>\n        <mo stretchy="false">(</mo>\n        <msub>\n          <mi>x</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>n</mi>\n          </mrow>\n        </msub>\n        <mo>,</mo>\n        <msub>\n          <mi>y</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>n</mi>\n          </mrow>\n        </msub>\n        <mo stretchy="false">)</mo>\n        <mo fence="false" stretchy="false">}</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle D=\\{(x_{1},y_{1})\\dots ,(x_{n},y_{n})\\}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/757190ec5d200f1ca40a0d23e32f090a12352b6d" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:27.049ex; height:2.843ex;" alt="{\\displaystyle D=\\{(x_{1},y_{1})\\dots ,(x_{n},y_{n})\\}}"/></span>, all sampled from the same joint distribution <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle P(x,y)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>P</mi>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo>,</mo>\n        <mi>y</mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle P(x,y)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d5b3d8f37f5458c22b61eaf26e5af0523acb63e2" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:7.074ex; height:2.843ex;" alt="P(x,y)"/></span>. The three terms represent:\n</p>\n<ul><li>the square of the <i>bias</i> of the learning method, which can be thought of as the error caused by the simplifying assumptions built into the method. E.g., when approximating a non-linear function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle f(x)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>f</mi>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle f(x)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/202945cce41ecebb6f643f31d119c514bec7a074" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:4.418ex; height:2.843ex;" alt="f(x)"/></span> using a learning method for <a href="/wiki/Linear_model" title="Linear model">linear models</a>, there will be error in the estimates <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle {\\hat {f}}(x)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>f</mi>\n              <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle {\\hat {f}}(x)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/def60945c876ae17c5a91167971245424f2006f6" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:4.838ex; height:3.343ex;" alt="\\hat{f}(x)"/></span> due to this assumption;</li>\n<li>the <i>variance</i> of the learning method, or, intuitively, how much the learning method <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle {\\hat {f}}(x)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>f</mi>\n              <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle {\\hat {f}}(x)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/def60945c876ae17c5a91167971245424f2006f6" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:4.838ex; height:3.343ex;" alt="\\hat{f}(x)"/></span> will move around its mean;</li>\n<li>the irreducible error <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\sigma ^{2}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msup>\n          <mi>&#x03C3;<!-- \xcf\x83 --></mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>2</mn>\n          </mrow>\n        </msup>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\sigma ^{2}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/53a5c55e536acf250c1d3e0f754be5692b843ef5" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:2.385ex; height:2.676ex;" alt="\\sigma ^{2}"/></span>.</li></ul>\n<p>Since all three terms are non-negative, this forms a lower bound on the expected error on unseen samples.<sup id="cite_ref-islr_7-1" class="reference"><a href="#cite_note-islr-7">&#91;7&#93;</a></sup><sup class="reference" style="white-space:nowrap;">:<span>34</span></sup>\n</p><p>The more complex the model <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle {\\hat {f}}(x)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>f</mi>\n              <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle {\\hat {f}}(x)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/def60945c876ae17c5a91167971245424f2006f6" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:4.838ex; height:3.343ex;" alt="\\hat{f}(x)"/></span> is, the more data points it will capture, and the lower the bias will be. However, complexity will make the model "move" more to capture the data points, and hence its variance will be larger.\n</p>\n<h3><span class="mw-headline" id="Derivation">Derivation</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Bias%E2%80%93variance_tradeoff&amp;action=edit&amp;section=3" title="Edit section: Derivation">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p>The derivation of the bias\xe2\x80\x93variance decomposition for squared error proceeds as follows.<sup id="cite_ref-9" class="reference"><a href="#cite_note-9">&#91;9&#93;</a></sup><sup id="cite_ref-10" class="reference"><a href="#cite_note-10">&#91;10&#93;</a></sup> For notational convenience, we abbreviate <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle f=f(x)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>f</mi>\n        <mo>=</mo>\n        <mi>f</mi>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle f=f(x)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a8982ea0271b9a6b8036cd2a883000a59f5a1ab9" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:8.795ex; height:2.843ex;" alt="f = f(x)"/></span>, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle {\\hat {f}}={\\hat {f}}(x;D)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>f</mi>\n              <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo>=</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>f</mi>\n              <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo>;</mo>\n        <mi>D</mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle {\\hat {f}}={\\hat {f}}(x;D)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5d13a9cdcbd8adcdb91352a02eb61129c669bf74" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:12.594ex; height:3.343ex;" alt="{\\displaystyle {\\hat {f}}={\\hat {f}}(x;D)}"/></span> and we drop the <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle D}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>D</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle D}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f34a0c600395e5d4345287e21fb26efd386990e6" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.924ex; height:2.176ex;" alt="D"/></span> subscript on our expectation operators. First, recall that, by definition, for any random variable <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle X}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>X</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle X}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.98ex; height:2.176ex;" alt="X"/></span>, we have\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\operatorname {Var} [X]=\\operatorname {E} [X^{2}]-\\operatorname {E} [X]^{2}.}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>Var</mi>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mo stretchy="false">[</mo>\n        <mi>X</mi>\n        <mo stretchy="false">]</mo>\n        <mo>=</mo>\n        <mi mathvariant="normal">E</mi>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mo stretchy="false">[</mo>\n        <msup>\n          <mi>X</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>2</mn>\n          </mrow>\n        </msup>\n        <mo stretchy="false">]</mo>\n        <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n        <mi mathvariant="normal">E</mi>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mo stretchy="false">[</mo>\n        <mi>X</mi>\n        <msup>\n          <mo stretchy="false">]</mo>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>2</mn>\n          </mrow>\n        </msup>\n        <mo>.</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\operatorname {Var} [X]=\\operatorname {E} [X^{2}]-\\operatorname {E} [X]^{2}.}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/859ae1bcb7d66a8abb2e804653215eb9eafb896b" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:25.515ex; height:3.176ex;" alt="{\\displaystyle \\operatorname {Var} [X]=\\operatorname {E} [X^{2}]-\\operatorname {E} [X]^{2}.}"/></span></dd></dl>\n<p>Rearranging, we get:\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\operatorname {E} [X^{2}]=\\operatorname {Var} [X]+\\operatorname {E} [X]^{2}.}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi mathvariant="normal">E</mi>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mo stretchy="false">[</mo>\n        <msup>\n          <mi>X</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>2</mn>\n          </mrow>\n        </msup>\n        <mo stretchy="false">]</mo>\n        <mo>=</mo>\n        <mi>Var</mi>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mo stretchy="false">[</mo>\n        <mi>X</mi>\n        <mo stretchy="false">]</mo>\n        <mo>+</mo>\n        <mi mathvariant="normal">E</mi>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mo stretchy="false">[</mo>\n        <mi>X</mi>\n        <msup>\n          <mo stretchy="false">]</mo>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>2</mn>\n          </mrow>\n        </msup>\n        <mo>.</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\operatorname {E} [X^{2}]=\\operatorname {Var} [X]+\\operatorname {E} [X]^{2}.}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/650c128cd4c4f64cdc7f2e29c6cc3929d8e92b88" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:25.515ex; height:3.176ex;" alt="{\\displaystyle \\operatorname {E} [X^{2}]=\\operatorname {Var} [X]+\\operatorname {E} [X]^{2}.}"/></span></dd></dl>\n<p>Since <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle f}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>f</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle f}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.279ex; height:2.509ex;" alt="f"/></span> is <a href="/wiki/Deterministic_algorithm" title="Deterministic algorithm">deterministic</a>, i.e. independent of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle D}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>D</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle D}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f34a0c600395e5d4345287e21fb26efd386990e6" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.924ex; height:2.176ex;" alt="D"/></span>,\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\operatorname {E} [f]=f.}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi mathvariant="normal">E</mi>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mo stretchy="false">[</mo>\n        <mi>f</mi>\n        <mo stretchy="false">]</mo>\n        <mo>=</mo>\n        <mi>f</mi>\n        <mo>.</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\operatorname {E} [f]=f.}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e4cc9a0668ccec054ec20f2d518495ea0aa46e61" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:9.179ex; height:2.843ex;" alt="{\\displaystyle \\operatorname {E} [f]=f.}"/></span></dd></dl>\n<p>Thus, given <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle y=f+\\varepsilon }">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>y</mi>\n        <mo>=</mo>\n        <mi>f</mi>\n        <mo>+</mo>\n        <mi>&#x03B5;<!-- \xce\xb5 --></mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle y=f+\\varepsilon }</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f4e3b37184854b796cb4323f3f1c6285760c70d9" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:9.456ex; height:2.509ex;" alt="{\\displaystyle y=f+\\varepsilon }"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\operatorname {E} [\\varepsilon ]=0}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi mathvariant="normal">E</mi>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mo stretchy="false">[</mo>\n        <mi>&#x03B5;<!-- \xce\xb5 --></mi>\n        <mo stretchy="false">]</mo>\n        <mo>=</mo>\n        <mn>0</mn>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\operatorname {E} [\\varepsilon ]=0}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a9494698413723204253e82aaff8b02684a64ed6" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:8.221ex; height:2.843ex;" alt="{\\displaystyle \\operatorname {E} [\\varepsilon ]=0}"/></span> (because <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\varepsilon }">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>&#x03B5;<!-- \xce\xb5 --></mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\varepsilon }</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a30c89172e5b88edbd45d3e2772c7f5e562e5173" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.083ex; height:1.676ex;" alt="\\varepsilon "/></span> is noise), implies <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\operatorname {E} [y]=\\operatorname {E} [f+\\varepsilon ]=\\operatorname {E} [f]=f.}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi mathvariant="normal">E</mi>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mo stretchy="false">[</mo>\n        <mi>y</mi>\n        <mo stretchy="false">]</mo>\n        <mo>=</mo>\n        <mi mathvariant="normal">E</mi>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mo stretchy="false">[</mo>\n        <mi>f</mi>\n        <mo>+</mo>\n        <mi>&#x03B5;<!-- \xce\xb5 --></mi>\n        <mo stretchy="false">]</mo>\n        <mo>=</mo>\n        <mi mathvariant="normal">E</mi>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mo stretchy="false">[</mo>\n        <mi>f</mi>\n        <mo stretchy="false">]</mo>\n        <mo>=</mo>\n        <mi>f</mi>\n        <mo>.</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\operatorname {E} [y]=\\operatorname {E} [f+\\varepsilon ]=\\operatorname {E} [f]=f.}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/fd5be0da3a9300d8822afa6080b3d404cf33bb18" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:27.487ex; height:2.843ex;" alt="{\\displaystyle \\operatorname {E} [y]=\\operatorname {E} [f+\\varepsilon ]=\\operatorname {E} [f]=f.}"/></span>\n</p><p>Also, since <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\operatorname {Var} [\\varepsilon ]=\\sigma ^{2},}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>Var</mi>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mo stretchy="false">[</mo>\n        <mi>&#x03B5;<!-- \xce\xb5 --></mi>\n        <mo stretchy="false">]</mo>\n        <mo>=</mo>\n        <msup>\n          <mi>&#x03C3;<!-- \xcf\x83 --></mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>2</mn>\n          </mrow>\n        </msup>\n        <mo>,</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\operatorname {Var} [\\varepsilon ]=\\sigma ^{2},}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e1d4c278d7174310f125f7f1625b204d6c9ef6b7" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:12.324ex; height:3.176ex;" alt="{\\displaystyle \\operatorname {Var} [\\varepsilon ]=\\sigma ^{2},}"/></span>\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\operatorname {Var} [y]=\\operatorname {E} [(y-\\operatorname {E} [y])^{2}]=\\operatorname {E} [(y-f)^{2}]=\\operatorname {E} [(f+\\varepsilon -f)^{2}]=\\operatorname {E} [\\varepsilon ^{2}]=\\operatorname {Var} [\\varepsilon ]+\\operatorname {E} [\\varepsilon ]^{2}=\\sigma ^{2}+0^{2}=\\sigma ^{2}.}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>Var</mi>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mo stretchy="false">[</mo>\n        <mi>y</mi>\n        <mo stretchy="false">]</mo>\n        <mo>=</mo>\n        <mi mathvariant="normal">E</mi>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mo stretchy="false">[</mo>\n        <mo stretchy="false">(</mo>\n        <mi>y</mi>\n        <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n        <mi mathvariant="normal">E</mi>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mo stretchy="false">[</mo>\n        <mi>y</mi>\n        <mo stretchy="false">]</mo>\n        <msup>\n          <mo stretchy="false">)</mo>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>2</mn>\n          </mrow>\n        </msup>\n        <mo stretchy="false">]</mo>\n        <mo>=</mo>\n        <mi mathvariant="normal">E</mi>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mo stretchy="false">[</mo>\n        <mo stretchy="false">(</mo>\n        <mi>y</mi>\n        <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n        <mi>f</mi>\n        <msup>\n          <mo stretchy="false">)</mo>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>2</mn>\n          </mrow>\n        </msup>\n        <mo stretchy="false">]</mo>\n        <mo>=</mo>\n        <mi mathvariant="normal">E</mi>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mo stretchy="false">[</mo>\n        <mo stretchy="false">(</mo>\n        <mi>f</mi>\n        <mo>+</mo>\n        <mi>&#x03B5;<!-- \xce\xb5 --></mi>\n        <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n        <mi>f</mi>\n        <msup>\n          <mo stretchy="false">)</mo>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>2</mn>\n          </mrow>\n        </msup>\n        <mo stretchy="false">]</mo>\n        <mo>=</mo>\n        <mi mathvariant="normal">E</mi>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mo stretchy="false">[</mo>\n        <msup>\n          <mi>&#x03B5;<!-- \xce\xb5 --></mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>2</mn>\n          </mrow>\n        </msup>\n        <mo stretchy="false">]</mo>\n        <mo>=</mo>\n        <mi>Var</mi>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mo stretchy="false">[</mo>\n        <mi>&#x03B5;<!-- \xce\xb5 --></mi>\n        <mo stretchy="false">]</mo>\n        <mo>+</mo>\n        <mi mathvariant="normal">E</mi>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mo stretchy="false">[</mo>\n        <mi>&#x03B5;<!-- \xce\xb5 --></mi>\n        <msup>\n          <mo stretchy="false">]</mo>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>2</mn>\n          </mrow>\n        </msup>\n        <mo>=</mo>\n        <msup>\n          <mi>&#x03C3;<!-- \xcf\x83 --></mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>2</mn>\n          </mrow>\n        </msup>\n        <mo>+</mo>\n        <msup>\n          <mn>0</mn>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>2</mn>\n          </mrow>\n        </msup>\n        <mo>=</mo>\n        <msup>\n          <mi>&#x03C3;<!-- \xcf\x83 --></mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>2</mn>\n          </mrow>\n        </msup>\n        <mo>.</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\operatorname {Var} [y]=\\operatorname {E} [(y-\\operatorname {E} [y])^{2}]=\\operatorname {E} [(y-f)^{2}]=\\operatorname {E} [(f+\\varepsilon -f)^{2}]=\\operatorname {E} [\\varepsilon ^{2}]=\\operatorname {Var} [\\varepsilon ]+\\operatorname {E} [\\varepsilon ]^{2}=\\sigma ^{2}+0^{2}=\\sigma ^{2}.}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3f73227c8ec8bc01a978efd4bcfce94e524c73c5" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:97.336ex; height:3.176ex;" alt="{\\displaystyle \\operatorname {Var} [y]=\\operatorname {E} [(y-\\operatorname {E} [y])^{2}]=\\operatorname {E} [(y-f)^{2}]=\\operatorname {E} [(f+\\varepsilon -f)^{2}]=\\operatorname {E} [\\varepsilon ^{2}]=\\operatorname {Var} [\\varepsilon ]+\\operatorname {E} [\\varepsilon ]^{2}=\\sigma ^{2}+0^{2}=\\sigma ^{2}.}"/></span></dd></dl>\n<p>Thus, since <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\varepsilon }">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>&#x03B5;<!-- \xce\xb5 --></mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\varepsilon }</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a30c89172e5b88edbd45d3e2772c7f5e562e5173" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.083ex; height:1.676ex;" alt="\\varepsilon "/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle {\\hat {f}}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>f</mi>\n              <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle {\\hat {f}}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/14ce989fd75da938ec6f95a0cdb71037b23a11cb" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.699ex; height:3.176ex;" alt="{\\hat {f}}"/></span> are independent, we can write\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle {\\begin{aligned}\\operatorname {E} {\\big [}(y-{\\hat {f}})^{2}{\\big ]}&amp;=\\operatorname {E} {\\big [}(f+\\varepsilon -{\\hat {f}})^{2}{\\big ]}\\\\[5pt]&amp;=\\operatorname {E} {\\big [}(f+\\varepsilon -{\\hat {f}}+\\operatorname {E} [{\\hat {f}}]-\\operatorname {E} [{\\hat {f}}])^{2}{\\big ]}\\\\[5pt]&amp;=\\operatorname {E} {\\big [}(f-\\operatorname {E} [{\\hat {f}}])^{2}{\\big ]}+\\operatorname {E} [\\varepsilon ^{2}]+\\operatorname {E} {\\big [}(\\operatorname {E} [{\\hat {f}}]-{\\hat {f}})^{2}{\\big ]}+2\\operatorname {E} {\\big [}(f-\\operatorname {E} [{\\hat {f}}])\\varepsilon {\\big ]}+2\\operatorname {E} {\\big [}\\varepsilon (\\operatorname {E} [{\\hat {f}}]-{\\hat {f}}){\\big ]}+2\\operatorname {E} {\\big [}(\\operatorname {E} [{\\hat {f}}]-{\\hat {f}})(f-\\operatorname {E} [{\\hat {f}}]){\\big ]}\\\\[5pt]&amp;=(f-\\operatorname {E} [{\\hat {f}}])^{2}+\\operatorname {E} [\\varepsilon ^{2}]+\\operatorname {E} {\\big [}(\\operatorname {E} [{\\hat {f}}]-{\\hat {f}})^{2}{\\big ]}+2(f-\\operatorname {E} [{\\hat {f}}])\\operatorname {E} [\\varepsilon ]+2\\operatorname {E} [\\varepsilon ]\\operatorname {E} {\\big [}\\operatorname {E} [{\\hat {f}}]-{\\hat {f}}{\\big ]}+2\\operatorname {E} {\\big [}\\operatorname {E} [{\\hat {f}}]-{\\hat {f}}{\\big ]}(f-\\operatorname {E} [{\\hat {f}}])\\\\[5pt]&amp;=(f-\\operatorname {E} [{\\hat {f}}])^{2}+\\operatorname {E} [\\varepsilon ^{2}]+\\operatorname {E} {\\big [}(\\operatorname {E} [{\\hat {f}}]-{\\hat {f}})^{2}{\\big ]}\\\\[5pt]&amp;=(f-\\operatorname {E} [{\\hat {f}}])^{2}+\\operatorname {Var} [\\varepsilon ]+\\operatorname {Var} {\\big [}{\\hat {f}}{\\big ]}\\\\[5pt]&amp;=\\operatorname {Bias} [{\\hat {f}}]^{2}+\\operatorname {Var} [\\varepsilon ]+\\operatorname {Var} {\\big [}{\\hat {f}}{\\big ]}\\\\[5pt]&amp;=\\operatorname {Bias} [{\\hat {f}}]^{2}+\\sigma ^{2}+\\operatorname {Var} {\\big [}{\\hat {f}}{\\big ]}.\\end{aligned}}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mrow class="MJX-TeXAtom-ORD">\n          <mtable columnalign="right left right left right left right left right left right left" rowspacing="0.8em 0.8em 0.8em 0.8em 0.8em 0.8em 0.8em 0.3em" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true">\n            <mtr>\n              <mtd>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mo maxsize="1.2em" minsize="1.2em">[</mo>\n                  </mrow>\n                </mrow>\n                <mo stretchy="false">(</mo>\n                <mi>y</mi>\n                <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <msup>\n                  <mo stretchy="false">)</mo>\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mn>2</mn>\n                  </mrow>\n                </msup>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mo maxsize="1.2em" minsize="1.2em">]</mo>\n                  </mrow>\n                </mrow>\n              </mtd>\n              <mtd>\n                <mi></mi>\n                <mo>=</mo>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mo maxsize="1.2em" minsize="1.2em">[</mo>\n                  </mrow>\n                </mrow>\n                <mo stretchy="false">(</mo>\n                <mi>f</mi>\n                <mo>+</mo>\n                <mi>&#x03B5;<!-- \xce\xb5 --></mi>\n                <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <msup>\n                  <mo stretchy="false">)</mo>\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mn>2</mn>\n                  </mrow>\n                </msup>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mo maxsize="1.2em" minsize="1.2em">]</mo>\n                  </mrow>\n                </mrow>\n              </mtd>\n            </mtr>\n            <mtr>\n              <mtd />\n              <mtd>\n                <mi></mi>\n                <mo>=</mo>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mo maxsize="1.2em" minsize="1.2em">[</mo>\n                  </mrow>\n                </mrow>\n                <mo stretchy="false">(</mo>\n                <mi>f</mi>\n                <mo>+</mo>\n                <mi>&#x03B5;<!-- \xce\xb5 --></mi>\n                <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <mo>+</mo>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mo stretchy="false">[</mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <mo stretchy="false">]</mo>\n                <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mo stretchy="false">[</mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <mo stretchy="false">]</mo>\n                <msup>\n                  <mo stretchy="false">)</mo>\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mn>2</mn>\n                  </mrow>\n                </msup>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mo maxsize="1.2em" minsize="1.2em">]</mo>\n                  </mrow>\n                </mrow>\n              </mtd>\n            </mtr>\n            <mtr>\n              <mtd />\n              <mtd>\n                <mi></mi>\n                <mo>=</mo>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mo maxsize="1.2em" minsize="1.2em">[</mo>\n                  </mrow>\n                </mrow>\n                <mo stretchy="false">(</mo>\n                <mi>f</mi>\n                <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mo stretchy="false">[</mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <mo stretchy="false">]</mo>\n                <msup>\n                  <mo stretchy="false">)</mo>\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mn>2</mn>\n                  </mrow>\n                </msup>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mo maxsize="1.2em" minsize="1.2em">]</mo>\n                  </mrow>\n                </mrow>\n                <mo>+</mo>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mo stretchy="false">[</mo>\n                <msup>\n                  <mi>&#x03B5;<!-- \xce\xb5 --></mi>\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mn>2</mn>\n                  </mrow>\n                </msup>\n                <mo stretchy="false">]</mo>\n                <mo>+</mo>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mo maxsize="1.2em" minsize="1.2em">[</mo>\n                  </mrow>\n                </mrow>\n                <mo stretchy="false">(</mo>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mo stretchy="false">[</mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <mo stretchy="false">]</mo>\n                <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <msup>\n                  <mo stretchy="false">)</mo>\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mn>2</mn>\n                  </mrow>\n                </msup>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mo maxsize="1.2em" minsize="1.2em">]</mo>\n                  </mrow>\n                </mrow>\n                <mo>+</mo>\n                <mn>2</mn>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mo maxsize="1.2em" minsize="1.2em">[</mo>\n                  </mrow>\n                </mrow>\n                <mo stretchy="false">(</mo>\n                <mi>f</mi>\n                <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mo stretchy="false">[</mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <mo stretchy="false">]</mo>\n                <mo stretchy="false">)</mo>\n                <mi>&#x03B5;<!-- \xce\xb5 --></mi>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mo maxsize="1.2em" minsize="1.2em">]</mo>\n                  </mrow>\n                </mrow>\n                <mo>+</mo>\n                <mn>2</mn>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mo maxsize="1.2em" minsize="1.2em">[</mo>\n                  </mrow>\n                </mrow>\n                <mi>&#x03B5;<!-- \xce\xb5 --></mi>\n                <mo stretchy="false">(</mo>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mo stretchy="false">[</mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <mo stretchy="false">]</mo>\n                <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <mo stretchy="false">)</mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mo maxsize="1.2em" minsize="1.2em">]</mo>\n                  </mrow>\n                </mrow>\n                <mo>+</mo>\n                <mn>2</mn>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mo maxsize="1.2em" minsize="1.2em">[</mo>\n                  </mrow>\n                </mrow>\n                <mo stretchy="false">(</mo>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mo stretchy="false">[</mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <mo stretchy="false">]</mo>\n                <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <mo stretchy="false">)</mo>\n                <mo stretchy="false">(</mo>\n                <mi>f</mi>\n                <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mo stretchy="false">[</mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <mo stretchy="false">]</mo>\n                <mo stretchy="false">)</mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mo maxsize="1.2em" minsize="1.2em">]</mo>\n                  </mrow>\n                </mrow>\n              </mtd>\n            </mtr>\n            <mtr>\n              <mtd />\n              <mtd>\n                <mi></mi>\n                <mo>=</mo>\n                <mo stretchy="false">(</mo>\n                <mi>f</mi>\n                <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mo stretchy="false">[</mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <mo stretchy="false">]</mo>\n                <msup>\n                  <mo stretchy="false">)</mo>\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mn>2</mn>\n                  </mrow>\n                </msup>\n                <mo>+</mo>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mo stretchy="false">[</mo>\n                <msup>\n                  <mi>&#x03B5;<!-- \xce\xb5 --></mi>\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mn>2</mn>\n                  </mrow>\n                </msup>\n                <mo stretchy="false">]</mo>\n                <mo>+</mo>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mo maxsize="1.2em" minsize="1.2em">[</mo>\n                  </mrow>\n                </mrow>\n                <mo stretchy="false">(</mo>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mo stretchy="false">[</mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <mo stretchy="false">]</mo>\n                <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <msup>\n                  <mo stretchy="false">)</mo>\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mn>2</mn>\n                  </mrow>\n                </msup>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mo maxsize="1.2em" minsize="1.2em">]</mo>\n                  </mrow>\n                </mrow>\n                <mo>+</mo>\n                <mn>2</mn>\n                <mo stretchy="false">(</mo>\n                <mi>f</mi>\n                <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mo stretchy="false">[</mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <mo stretchy="false">]</mo>\n                <mo stretchy="false">)</mo>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mo stretchy="false">[</mo>\n                <mi>&#x03B5;<!-- \xce\xb5 --></mi>\n                <mo stretchy="false">]</mo>\n                <mo>+</mo>\n                <mn>2</mn>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mo stretchy="false">[</mo>\n                <mi>&#x03B5;<!-- \xce\xb5 --></mi>\n                <mo stretchy="false">]</mo>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mo maxsize="1.2em" minsize="1.2em">[</mo>\n                  </mrow>\n                </mrow>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mo stretchy="false">[</mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <mo stretchy="false">]</mo>\n                <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mo maxsize="1.2em" minsize="1.2em">]</mo>\n                  </mrow>\n                </mrow>\n                <mo>+</mo>\n                <mn>2</mn>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mo maxsize="1.2em" minsize="1.2em">[</mo>\n                  </mrow>\n                </mrow>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mo stretchy="false">[</mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <mo stretchy="false">]</mo>\n                <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mo maxsize="1.2em" minsize="1.2em">]</mo>\n                  </mrow>\n                </mrow>\n                <mo stretchy="false">(</mo>\n                <mi>f</mi>\n                <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mo stretchy="false">[</mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <mo stretchy="false">]</mo>\n                <mo stretchy="false">)</mo>\n              </mtd>\n            </mtr>\n            <mtr>\n              <mtd />\n              <mtd>\n                <mi></mi>\n                <mo>=</mo>\n                <mo stretchy="false">(</mo>\n                <mi>f</mi>\n                <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mo stretchy="false">[</mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <mo stretchy="false">]</mo>\n                <msup>\n                  <mo stretchy="false">)</mo>\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mn>2</mn>\n                  </mrow>\n                </msup>\n                <mo>+</mo>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mo stretchy="false">[</mo>\n                <msup>\n                  <mi>&#x03B5;<!-- \xce\xb5 --></mi>\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mn>2</mn>\n                  </mrow>\n                </msup>\n                <mo stretchy="false">]</mo>\n                <mo>+</mo>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mo maxsize="1.2em" minsize="1.2em">[</mo>\n                  </mrow>\n                </mrow>\n                <mo stretchy="false">(</mo>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mo stretchy="false">[</mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <mo stretchy="false">]</mo>\n                <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <msup>\n                  <mo stretchy="false">)</mo>\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mn>2</mn>\n                  </mrow>\n                </msup>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mo maxsize="1.2em" minsize="1.2em">]</mo>\n                  </mrow>\n                </mrow>\n              </mtd>\n            </mtr>\n            <mtr>\n              <mtd />\n              <mtd>\n                <mi></mi>\n                <mo>=</mo>\n                <mo stretchy="false">(</mo>\n                <mi>f</mi>\n                <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n                <mi mathvariant="normal">E</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mo stretchy="false">[</mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <mo stretchy="false">]</mo>\n                <msup>\n                  <mo stretchy="false">)</mo>\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mn>2</mn>\n                  </mrow>\n                </msup>\n                <mo>+</mo>\n                <mi>Var</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mo stretchy="false">[</mo>\n                <mi>&#x03B5;<!-- \xce\xb5 --></mi>\n                <mo stretchy="false">]</mo>\n                <mo>+</mo>\n                <mi>Var</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mo maxsize="1.2em" minsize="1.2em">[</mo>\n                  </mrow>\n                </mrow>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mo maxsize="1.2em" minsize="1.2em">]</mo>\n                  </mrow>\n                </mrow>\n              </mtd>\n            </mtr>\n            <mtr>\n              <mtd />\n              <mtd>\n                <mi></mi>\n                <mo>=</mo>\n                <mi>Bias</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mo stretchy="false">[</mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <msup>\n                  <mo stretchy="false">]</mo>\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mn>2</mn>\n                  </mrow>\n                </msup>\n                <mo>+</mo>\n                <mi>Var</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mo stretchy="false">[</mo>\n                <mi>&#x03B5;<!-- \xce\xb5 --></mi>\n                <mo stretchy="false">]</mo>\n                <mo>+</mo>\n                <mi>Var</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mo maxsize="1.2em" minsize="1.2em">[</mo>\n                  </mrow>\n                </mrow>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mo maxsize="1.2em" minsize="1.2em">]</mo>\n                  </mrow>\n                </mrow>\n              </mtd>\n            </mtr>\n            <mtr>\n              <mtd />\n              <mtd>\n                <mi></mi>\n                <mo>=</mo>\n                <mi>Bias</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mo stretchy="false">[</mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <msup>\n                  <mo stretchy="false">]</mo>\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mn>2</mn>\n                  </mrow>\n                </msup>\n                <mo>+</mo>\n                <msup>\n                  <mi>&#x03C3;<!-- \xcf\x83 --></mi>\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mn>2</mn>\n                  </mrow>\n                </msup>\n                <mo>+</mo>\n                <mi>Var</mi>\n                <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mo maxsize="1.2em" minsize="1.2em">[</mo>\n                  </mrow>\n                </mrow>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mover>\n                      <mi>f</mi>\n                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n                    </mover>\n                  </mrow>\n                </mrow>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mo maxsize="1.2em" minsize="1.2em">]</mo>\n                  </mrow>\n                </mrow>\n                <mo>.</mo>\n              </mtd>\n            </mtr>\n          </mtable>\n        </mrow>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle {\\begin{aligned}\\operatorname {E} {\\big [}(y-{\\hat {f}})^{2}{\\big ]}&amp;=\\operatorname {E} {\\big [}(f+\\varepsilon -{\\hat {f}})^{2}{\\big ]}\\\\[5pt]&amp;=\\operatorname {E} {\\big [}(f+\\varepsilon -{\\hat {f}}+\\operatorname {E} [{\\hat {f}}]-\\operatorname {E} [{\\hat {f}}])^{2}{\\big ]}\\\\[5pt]&amp;=\\operatorname {E} {\\big [}(f-\\operatorname {E} [{\\hat {f}}])^{2}{\\big ]}+\\operatorname {E} [\\varepsilon ^{2}]+\\operatorname {E} {\\big [}(\\operatorname {E} [{\\hat {f}}]-{\\hat {f}})^{2}{\\big ]}+2\\operatorname {E} {\\big [}(f-\\operatorname {E} [{\\hat {f}}])\\varepsilon {\\big ]}+2\\operatorname {E} {\\big [}\\varepsilon (\\operatorname {E} [{\\hat {f}}]-{\\hat {f}}){\\big ]}+2\\operatorname {E} {\\big [}(\\operatorname {E} [{\\hat {f}}]-{\\hat {f}})(f-\\operatorname {E} [{\\hat {f}}]){\\big ]}\\\\[5pt]&amp;=(f-\\operatorname {E} [{\\hat {f}}])^{2}+\\operatorname {E} [\\varepsilon ^{2}]+\\operatorname {E} {\\big [}(\\operatorname {E} [{\\hat {f}}]-{\\hat {f}})^{2}{\\big ]}+2(f-\\operatorname {E} [{\\hat {f}}])\\operatorname {E} [\\varepsilon ]+2\\operatorname {E} [\\varepsilon ]\\operatorname {E} {\\big [}\\operatorname {E} [{\\hat {f}}]-{\\hat {f}}{\\big ]}+2\\operatorname {E} {\\big [}\\operatorname {E} [{\\hat {f}}]-{\\hat {f}}{\\big ]}(f-\\operatorname {E} [{\\hat {f}}])\\\\[5pt]&amp;=(f-\\operatorname {E} [{\\hat {f}}])^{2}+\\operatorname {E} [\\varepsilon ^{2}]+\\operatorname {E} {\\big [}(\\operatorname {E} [{\\hat {f}}]-{\\hat {f}})^{2}{\\big ]}\\\\[5pt]&amp;=(f-\\operatorname {E} [{\\hat {f}}])^{2}+\\operatorname {Var} [\\varepsilon ]+\\operatorname {Var} {\\big [}{\\hat {f}}{\\big ]}\\\\[5pt]&amp;=\\operatorname {Bias} [{\\hat {f}}]^{2}+\\operatorname {Var} [\\varepsilon ]+\\operatorname {Var} {\\big [}{\\hat {f}}{\\big ]}\\\\[5pt]&amp;=\\operatorname {Bias} [{\\hat {f}}]^{2}+\\sigma ^{2}+\\operatorname {Var} {\\big [}{\\hat {f}}{\\big ]}.\\end{aligned}}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c4b09d3706f759ff1adfbeda85765e16de39d36b" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -18.505ex; width:128.289ex; height:38.176ex;" alt="{\\displaystyle {\\begin{aligned}\\operatorname {E} {\\big [}(y-{\\hat {f}})^{2}{\\big ]}&amp;=\\operatorname {E} {\\big [}(f+\\varepsilon -{\\hat {f}})^{2}{\\big ]}\\\\[5pt]&amp;=\\operatorname {E} {\\big [}(f+\\varepsilon -{\\hat {f}}+\\operatorname {E} [{\\hat {f}}]-\\operatorname {E} [{\\hat {f}}])^{2}{\\big ]}\\\\[5pt]&amp;=\\operatorname {E} {\\big [}(f-\\operatorname {E} [{\\hat {f}}])^{2}{\\big ]}+\\operatorname {E} [\\varepsilon ^{2}]+\\operatorname {E} {\\big [}(\\operatorname {E} [{\\hat {f}}]-{\\hat {f}})^{2}{\\big ]}+2\\operatorname {E} {\\big [}(f-\\operatorname {E} [{\\hat {f}}])\\varepsilon {\\big ]}+2\\operatorname {E} {\\big [}\\varepsilon (\\operatorname {E} [{\\hat {f}}]-{\\hat {f}}){\\big ]}+2\\operatorname {E} {\\big [}(\\operatorname {E} [{\\hat {f}}]-{\\hat {f}})(f-\\operatorname {E} [{\\hat {f}}]){\\big ]}\\\\[5pt]&amp;=(f-\\operatorname {E} [{\\hat {f}}])^{2}+\\operatorname {E} [\\varepsilon ^{2}]+\\operatorname {E} {\\big [}(\\operatorname {E} [{\\hat {f}}]-{\\hat {f}})^{2}{\\big ]}+2(f-\\operatorname {E} [{\\hat {f}}])\\operatorname {E} [\\varepsilon ]+2\\operatorname {E} [\\varepsilon ]\\operatorname {E} {\\big [}\\operatorname {E} [{\\hat {f}}]-{\\hat {f}}{\\big ]}+2\\operatorname {E} {\\big [}\\operatorname {E} [{\\hat {f}}]-{\\hat {f}}{\\big ]}(f-\\operatorname {E} [{\\hat {f}}])\\\\[5pt]&amp;=(f-\\operatorname {E} [{\\hat {f}}])^{2}+\\operatorname {E} [\\varepsilon ^{2}]+\\operatorname {E} {\\big [}(\\operatorname {E} [{\\hat {f}}]-{\\hat {f}})^{2}{\\big ]}\\\\[5pt]&amp;=(f-\\operatorname {E} [{\\hat {f}}])^{2}+\\operatorname {Var} [\\varepsilon ]+\\operatorname {Var} {\\big [}{\\hat {f}}{\\big ]}\\\\[5pt]&amp;=\\operatorname {Bias} [{\\hat {f}}]^{2}+\\operatorname {Var} [\\varepsilon ]+\\operatorname {Var} {\\big [}{\\hat {f}}{\\big ]}\\\\[5pt]&amp;=\\operatorname {Bias} [{\\hat {f}}]^{2}+\\sigma ^{2}+\\operatorname {Var} {\\big [}{\\hat {f}}{\\big ]}.\\end{aligned}}}"/></span></dd></dl>\n<p>Finally, MSE loss function (or negative log-likelihood) is obtained by taking the expectation value over <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle x\\sim P}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>x</mi>\n        <mo>&#x223C;<!-- \xe2\x88\xbc --></mo>\n        <mi>P</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle x\\sim P}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/22dca9c851a0f2939e608ad215bf42408aa95be8" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:6.174ex; height:2.176ex;" alt="{\\displaystyle x\\sim P}"/></span>:\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle {\\text{MSE}}=\\operatorname {E} _{x}{\\bigg \\{}\\operatorname {Bias} _{D}[{\\hat {f}}(x;D)]^{2}+\\operatorname {Var} _{D}{\\big [}{\\hat {f}}(x;D){\\big ]}{\\bigg \\}}+\\sigma ^{2}.}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mrow class="MJX-TeXAtom-ORD">\n          <mtext>MSE</mtext>\n        </mrow>\n        <mo>=</mo>\n        <msub>\n          <mi mathvariant="normal">E</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>x</mi>\n          </mrow>\n        </msub>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mo maxsize="2.047em" minsize="2.047em">{</mo>\n          </mrow>\n        </mrow>\n        <msub>\n          <mi>Bias</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>D</mi>\n          </mrow>\n        </msub>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mo stretchy="false">[</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>f</mi>\n              <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo>;</mo>\n        <mi>D</mi>\n        <mo stretchy="false">)</mo>\n        <msup>\n          <mo stretchy="false">]</mo>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>2</mn>\n          </mrow>\n        </msup>\n        <mo>+</mo>\n        <msub>\n          <mi>Var</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>D</mi>\n          </mrow>\n        </msub>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mo maxsize="1.2em" minsize="1.2em">[</mo>\n          </mrow>\n        </mrow>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>f</mi>\n              <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo>;</mo>\n        <mi>D</mi>\n        <mo stretchy="false">)</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mo maxsize="1.2em" minsize="1.2em">]</mo>\n          </mrow>\n        </mrow>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mo maxsize="2.047em" minsize="2.047em">}</mo>\n          </mrow>\n        </mrow>\n        <mo>+</mo>\n        <msup>\n          <mi>&#x03C3;<!-- \xcf\x83 --></mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>2</mn>\n          </mrow>\n        </msup>\n        <mo>.</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle {\\text{MSE}}=\\operatorname {E} _{x}{\\bigg \\{}\\operatorname {Bias} _{D}[{\\hat {f}}(x;D)]^{2}+\\operatorname {Var} _{D}{\\big [}{\\hat {f}}(x;D){\\big ]}{\\bigg \\}}+\\sigma ^{2}.}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/322402066ac32c4a24deac90cc7c32ceca8dc2ef" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.505ex; width:55.474ex; height:6.176ex;" alt="{\\displaystyle {\\text{MSE}}=\\operatorname {E} _{x}{\\bigg \\{}\\operatorname {Bias} _{D}[{\\hat {f}}(x;D)]^{2}+\\operatorname {Var} _{D}{\\big [}{\\hat {f}}(x;D){\\big ]}{\\bigg \\}}+\\sigma ^{2}.}"/></span></dd></dl>\n<h2><span class="mw-headline" id="Approaches">Approaches</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Bias%E2%80%93variance_tradeoff&amp;action=edit&amp;section=4" title="Edit section: Approaches">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<p><a href="/wiki/Dimensionality_reduction" title="Dimensionality reduction">Dimensionality reduction</a> and <a href="/wiki/Feature_selection" title="Feature selection">feature selection</a> can decrease variance by simplifying models. Similarly, a larger training set tends to decrease variance. Adding features (predictors) tends to decrease bias, at the expense of introducing additional variance. Learning algorithms typically have some tunable parameters that control bias and variance; for example,\n</p>\n<ul><li><a href="/wiki/Linear_model" title="Linear model">linear</a>  and <a href="/wiki/Generalized_linear_model" title="Generalized linear model">Generalized linear</a> models can be <a href="/wiki/Regularization_(mathematics)" title="Regularization (mathematics)">regularized</a> to decrease their variance at the cost of increasing their bias.<sup id="cite_ref-11" class="reference"><a href="#cite_note-11">&#91;11&#93;</a></sup></li>\n<li>In <a href="/wiki/Artificial_neural_network" title="Artificial neural network">artificial neural networks</a>, the variance increases and the bias decreases as the number of hidden units increase,<sup id="cite_ref-geman_12-0" class="reference"><a href="#cite_note-geman-12">&#91;12&#93;</a></sup> although this classical assumption has been the subject of recent debate.<sup id="cite_ref-neal2018_5-1" class="reference"><a href="#cite_note-neal2018-5">&#91;5&#93;</a></sup> Like in GLMs, regularization is typically applied.</li>\n<li>In <a href="/wiki/K-nearest_neighbor" class="mw-redirect" title="K-nearest neighbor"><i>k</i>-nearest neighbor</a> models, a high value of <span class="texhtml mvar" style="font-style:italic;">k</span> leads to high bias and low variance (see below).</li>\n<li>In <a href="/wiki/Instance-based_learning" title="Instance-based learning">instance-based learning</a>, regularization can be achieved varying the mixture of <a href="/wiki/Prototype" title="Prototype">prototypes</a> and exemplars.<sup id="cite_ref-13" class="reference"><a href="#cite_note-13">&#91;13&#93;</a></sup></li>\n<li>In <a href="/wiki/Decision_tree" title="Decision tree">decision trees</a>, the depth of the tree determines the variance. Decision trees are commonly pruned to control variance.<sup id="cite_ref-islr_7-2" class="reference"><a href="#cite_note-islr-7">&#91;7&#93;</a></sup><sup class="reference" style="white-space:nowrap;">:<span>307</span></sup></li></ul>\n<p>One way of resolving the trade-off is to use <a href="/wiki/Mixture_models" class="mw-redirect" title="Mixture models">mixture models</a> and <a href="/wiki/Ensemble_learning" title="Ensemble learning">ensemble learning</a>.<sup id="cite_ref-14" class="reference"><a href="#cite_note-14">&#91;14&#93;</a></sup><sup id="cite_ref-15" class="reference"><a href="#cite_note-15">&#91;15&#93;</a></sup> For example, <a href="/wiki/Boosting_(machine_learning)" title="Boosting (machine learning)">boosting</a> combines many "weak" (high bias) models in an ensemble that has lower bias than the individual models, while <a href="/wiki/Bootstrap_aggregating" title="Bootstrap aggregating">bagging</a> combines "strong" learners in a way that reduces their variance.  \n</p><p><a href="/wiki/Model_validation" class="mw-redirect" title="Model validation">Model validation</a> methods such as <a href="/wiki/Cross-validation_(statistics)" title="Cross-validation (statistics)">cross-validation (statistics)</a> can be used to tune models so as to optimize the trade-off. \n</p>\n<h3><span class="mw-headline" id="k-nearest_neighbors"><i>k</i>-nearest neighbors</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Bias%E2%80%93variance_tradeoff&amp;action=edit&amp;section=5" title="Edit section: k-nearest neighbors">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p>In the case of <a href="/wiki/K-nearest_neighbors_algorithm" title="K-nearest neighbors algorithm"><span class="texhtml mvar" style="font-style:italic;">k</span>-nearest neighbors regression</a>, when the expectation is taken over the possible labeling of a fixed training set, a <a href="/wiki/Closed-form_expression" title="Closed-form expression">closed-form expression</a> exists that relates the bias\xe2\x80\x93variance decomposition to the parameter <span class="texhtml mvar" style="font-style:italic;">k</span>:<sup id="cite_ref-ESL_8-1" class="reference"><a href="#cite_note-ESL-8">&#91;8&#93;</a></sup><sup class="reference" style="white-space:nowrap;">:<span>37, 223</span></sup>\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\operatorname {E} [(y-{\\hat {f}}(x))^{2}\\mid X=x]=\\left(f(x)-{\\frac {1}{k}}\\sum _{i=1}^{k}f(N_{i}(x))\\right)^{2}+{\\frac {\\sigma ^{2}}{k}}+\\sigma ^{2}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi mathvariant="normal">E</mi>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mo stretchy="false">[</mo>\n        <mo stretchy="false">(</mo>\n        <mi>y</mi>\n        <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>f</mi>\n              <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo stretchy="false">)</mo>\n        <msup>\n          <mo stretchy="false">)</mo>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>2</mn>\n          </mrow>\n        </msup>\n        <mo>&#x2223;<!-- \xe2\x88\xa3 --></mo>\n        <mi>X</mi>\n        <mo>=</mo>\n        <mi>x</mi>\n        <mo stretchy="false">]</mo>\n        <mo>=</mo>\n        <msup>\n          <mrow>\n            <mo>(</mo>\n            <mrow>\n              <mi>f</mi>\n              <mo stretchy="false">(</mo>\n              <mi>x</mi>\n              <mo stretchy="false">)</mo>\n              <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n              <mrow class="MJX-TeXAtom-ORD">\n                <mfrac>\n                  <mn>1</mn>\n                  <mi>k</mi>\n                </mfrac>\n              </mrow>\n              <munderover>\n                <mo>&#x2211;<!-- \xe2\x88\x91 --></mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mi>i</mi>\n                  <mo>=</mo>\n                  <mn>1</mn>\n                </mrow>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mi>k</mi>\n                </mrow>\n              </munderover>\n              <mi>f</mi>\n              <mo stretchy="false">(</mo>\n              <msub>\n                <mi>N</mi>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mi>i</mi>\n                </mrow>\n              </msub>\n              <mo stretchy="false">(</mo>\n              <mi>x</mi>\n              <mo stretchy="false">)</mo>\n              <mo stretchy="false">)</mo>\n            </mrow>\n            <mo>)</mo>\n          </mrow>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>2</mn>\n          </mrow>\n        </msup>\n        <mo>+</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mfrac>\n            <msup>\n              <mi>&#x03C3;<!-- \xcf\x83 --></mi>\n              <mrow class="MJX-TeXAtom-ORD">\n                <mn>2</mn>\n              </mrow>\n            </msup>\n            <mi>k</mi>\n          </mfrac>\n        </mrow>\n        <mo>+</mo>\n        <msup>\n          <mi>&#x03C3;<!-- \xcf\x83 --></mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>2</mn>\n          </mrow>\n        </msup>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\operatorname {E} [(y-{\\hat {f}}(x))^{2}\\mid X=x]=\\left(f(x)-{\\frac {1}{k}}\\sum _{i=1}^{k}f(N_{i}(x))\\right)^{2}+{\\frac {\\sigma ^{2}}{k}}+\\sigma ^{2}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/46dd9ffaa7af7d8738d2799f9f91df7c00d2118a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.171ex; width:64.367ex; height:8.009ex;" alt="{\\displaystyle \\operatorname {E} [(y-{\\hat {f}}(x))^{2}\\mid X=x]=\\left(f(x)-{\\frac {1}{k}}\\sum _{i=1}^{k}f(N_{i}(x))\\right)^{2}+{\\frac {\\sigma ^{2}}{k}}+\\sigma ^{2}}"/></span></dd></dl>\n<p>where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle N_{1}(x),\\dots ,N_{k}(x)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>N</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>1</mn>\n          </mrow>\n        </msub>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo stretchy="false">)</mo>\n        <mo>,</mo>\n        <mo>&#x2026;<!-- \xe2\x80\xa6 --></mo>\n        <mo>,</mo>\n        <msub>\n          <mi>N</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>k</mi>\n          </mrow>\n        </msub>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle N_{1}(x),\\dots ,N_{k}(x)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5835207a9f81fe493e2b77a4a3ab0ca773e4fc50" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:17.332ex; height:2.843ex;" alt="N_1(x), \\dots, N_k(x)"/></span> are the <span class="texhtml mvar" style="font-style:italic;">k</span> nearest neighbors of <span class="texhtml mvar" style="font-style:italic;">x</span> in the training set. The bias (first term) is a monotone rising function of <span class="texhtml mvar" style="font-style:italic;">k</span>, while the variance (second term) drops off as <span class="texhtml mvar" style="font-style:italic;">k</span> is increased. In fact, under "reasonable assumptions" the bias of the first-nearest neighbor (1-NN) estimator vanishes entirely as the size of the training set approaches infinity.<sup id="cite_ref-geman_12-1" class="reference"><a href="#cite_note-geman-12">&#91;12&#93;</a></sup>\n</p>\n<h2><span class="mw-headline" id="Applications">Applications</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Bias%E2%80%93variance_tradeoff&amp;action=edit&amp;section=6" title="Edit section: Applications">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<h3><span class="mw-headline" id="In_regression">In regression</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Bias%E2%80%93variance_tradeoff&amp;action=edit&amp;section=7" title="Edit section: In regression">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p>The bias\xe2\x80\x93variance decomposition forms the conceptual basis for regression <a href="/wiki/Regularization_(mathematics)" title="Regularization (mathematics)">regularization</a> methods such as <a href="/wiki/Lasso_(statistics)" title="Lasso (statistics)">Lasso</a> and <a href="/wiki/Ridge_regression" class="mw-redirect" title="Ridge regression">ridge regression</a>. Regularization methods introduce bias into the regression solution that can reduce variance considerably relative to the <a href="/wiki/Ordinary_least_squares" title="Ordinary least squares">ordinary least squares (OLS)</a> solution.  Although the OLS solution provides non-biased regression estimates, the lower variance solutions produced by regularization techniques provide superior MSE performance.\n</p>\n<h3><span class="mw-headline" id="In_classification">In classification</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Bias%E2%80%93variance_tradeoff&amp;action=edit&amp;section=8" title="Edit section: In classification">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p>The bias\xe2\x80\x93variance decomposition was originally formulated for least-squares regression. For the case of <a href="/wiki/Statistical_classification" title="Statistical classification">classification</a> under the <a href="/wiki/0-1_loss" class="mw-redirect" title="0-1 loss">0-1 loss</a> (misclassification rate), it is possible to find a similar decomposition.<sup id="cite_ref-16" class="reference"><a href="#cite_note-16">&#91;16&#93;</a></sup><sup id="cite_ref-17" class="reference"><a href="#cite_note-17">&#91;17&#93;</a></sup> Alternatively, if the classification problem can be phrased as <a href="/wiki/Probabilistic_classification" title="Probabilistic classification">probabilistic classification</a>, then the expected squared error of the predicted probabilities with respect to the true probabilities can be decomposed as before.<sup id="cite_ref-18" class="reference"><a href="#cite_note-18">&#91;18&#93;</a></sup>\n</p>\n<h3><span class="mw-headline" id="In_reinforcement_learning">In reinforcement learning</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Bias%E2%80%93variance_tradeoff&amp;action=edit&amp;section=9" title="Edit section: In reinforcement learning">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p>Even though the bias\xe2\x80\x93variance decomposition does not directly apply in <a href="/wiki/Reinforcement_learning" title="Reinforcement learning">reinforcement learning</a>, a similar tradeoff can also characterize generalization. When an agent has limited information on its environment, the suboptimality of an RL algorithm can be decomposed into the sum of two terms: a term related to an asymptotic bias and a term due to overfitting. The asymptotic bias is directly related to the learning algorithm (independently of the quantity of data) while the overfitting term comes from the fact that the amount of data is limited.<sup id="cite_ref-19" class="reference"><a href="#cite_note-19">&#91;19&#93;</a></sup>\n</p>\n<h3><span class="mw-headline" id="In_human_learning">In human learning</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Bias%E2%80%93variance_tradeoff&amp;action=edit&amp;section=10" title="Edit section: In human learning">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p>While widely discussed in the context of machine learning, the bias-variance dilemma has been examined in the context of <a href="/wiki/Cognitive_science" title="Cognitive science">human cognition</a>, most notably by <a href="/wiki/Gerd_Gigerenzer" title="Gerd Gigerenzer">Gerd Gigerenzer</a> and co-workers in the context of learned heuristics. They have argued (see references below) that the human brain resolves the dilemma in the case of the typically sparse, poorly-characterised training-sets provided by experience by adopting high-bias/low variance heuristics. This reflects the fact that a zero-bias approach has poor generalisability to new situations, and also unreasonably presumes precise knowledge of the true state of the world. The resulting heuristics are relatively simple, but produce better inferences in a wider variety of situations.<sup id="cite_ref-ReferenceA_20-0" class="reference"><a href="#cite_note-ReferenceA-20">&#91;20&#93;</a></sup>\n</p><p><a href="/wiki/Stuart_Geman" title="Stuart Geman">Geman</a> et al.<sup id="cite_ref-geman_12-2" class="reference"><a href="#cite_note-geman-12">&#91;12&#93;</a></sup> argue that the bias-variance dilemma implies that abilities such as generic <a href="/wiki/Object_recognition" class="mw-redirect" title="Object recognition">object recognition</a> cannot be learned from scratch, but require a certain degree of \xe2\x80\x9chard wiring\xe2\x80\x9d   that is later tuned by experience.  This is because model-free approaches to inference require impractically large training sets if they are to avoid high variance.\n</p>\n<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Bias%E2%80%93variance_tradeoff&amp;action=edit&amp;section=11" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<style data-mw-deduplicate="TemplateStyles:r998391716">.mw-parser-output .div-col{margin-top:0.3em;column-width:30em}.mw-parser-output .div-col-small{font-size:90%}.mw-parser-output .div-col-rules{column-rule:1px solid #aaa}.mw-parser-output .div-col dl,.mw-parser-output .div-col ol,.mw-parser-output .div-col ul{margin-top:0}.mw-parser-output .div-col li,.mw-parser-output .div-col dd{page-break-inside:avoid;break-inside:avoid-column}</style><div class="div-col" style="column-width: 25em;">\n<ul><li><a href="/wiki/Accuracy_and_precision" title="Accuracy and precision">Accuracy and precision</a></li>\n<li><a href="/wiki/Bias_of_an_estimator" title="Bias of an estimator">Bias of an estimator</a></li>\n<li><a href="/wiki/Gauss%E2%80%93Markov_theorem" title="Gauss\xe2\x80\x93Markov theorem">Gauss\xe2\x80\x93Markov theorem</a></li>\n<li><a href="/wiki/Hyperparameter_optimization" title="Hyperparameter optimization">Hyperparameter optimization</a></li>\n<li><a href="/wiki/Minimum-variance_unbiased_estimator" title="Minimum-variance unbiased estimator">Minimum-variance unbiased estimator</a></li>\n<li><a href="/wiki/Model_selection" title="Model selection">Model selection</a></li>\n<li><a href="/wiki/Regression_model_validation" class="mw-redirect" title="Regression model validation">Regression model validation</a></li>\n<li><a href="/wiki/Supervised_learning" title="Supervised learning">Supervised learning</a></li></ul>\n</div>\n<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Bias%E2%80%93variance_tradeoff&amp;action=edit&amp;section=12" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<div class="reflist" style="list-style-type: decimal;">\n<div class="mw-references-wrap mw-references-columns"><ol class="references">\n<li id="cite_note-1"><span class="mw-cite-backlink"><b><a href="#cite_ref-1">^</a></b></span> <span class="reference-text"><style data-mw-deduplicate="TemplateStyles:r999302996">.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:"\\"""\\"""\'""\'"}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}</style><cite id="CITEREFKohaviWolpert1996" class="citation journal cs1">Kohavi, Ron; Wolpert, David H. (1996). "Bias Plus Variance Decomposition for Zero-One Loss Functions". <i>ICML</i>. <b>96</b>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=ICML&amp;rft.atitle=Bias+Plus+Variance+Decomposition+for+Zero-One+Loss+Functions&amp;rft.volume=96&amp;rft.date=1996&amp;rft.aulast=Kohavi&amp;rft.aufirst=Ron&amp;rft.au=Wolpert%2C+David+H.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABias%E2%80%93variance+tradeoff" class="Z3988"></span></span>\n</li>\n<li id="cite_note-2"><span class="mw-cite-backlink"><b><a href="#cite_ref-2">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r999302996"/><cite id="CITEREFLuxburgSch\xc3\xb6lkopf2011" class="citation journal cs1">Luxburg, Ulrike V.; Sch\xc3\xb6lkopf, B. (2011). "Statistical learning theory: Models, concepts, and results". <i>Handbook of the History of Logic</i>. <b>10</b>: Section 2.4.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Handbook+of+the+History+of+Logic&amp;rft.atitle=Statistical+learning+theory%3A+Models%2C+concepts%2C+and+results&amp;rft.volume=10&amp;rft.pages=Section+2.4&amp;rft.date=2011&amp;rft.aulast=Luxburg&amp;rft.aufirst=Ulrike+V.&amp;rft.au=Sch%C3%B6lkopf%2C+B.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABias%E2%80%93variance+tradeoff" class="Z3988"></span></span>\n</li>\n<li id="cite_note-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-3">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r999302996"/><cite id="CITEREFDerumignySchmidt-Hieber" class="citation web cs1">Derumigny, Alexis; Schmidt-Hieber, Johannes. <a rel="nofollow" class="external text" href="https://arxiv.org/abs/2006.00278v1">"On lower bounds for the bias-variance trade-off"</a>. arXiv.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=On+lower+bounds+for+the+bias-variance+trade-off&amp;rft.pub=arXiv&amp;rft.aulast=Derumigny&amp;rft.aufirst=Alexis&amp;rft.au=Schmidt-Hieber%2C+Johannes&amp;rft_id=https%3A%2F%2Farxiv.org%2Fabs%2F2006.00278v1&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABias%E2%80%93variance+tradeoff" class="Z3988"></span></span>\n</li>\n<li id="cite_note-nealThesis2019-4"><span class="mw-cite-backlink"><b><a href="#cite_ref-nealThesis2019_4-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r999302996"/><cite id="CITEREFNeal2019" class="citation arxiv cs1">Neal, Brady (2019). "On the Bias-Variance Tradeoff: Textbooks Need an Update". <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/1912.08286">1912.08286</a></span> [<a rel="nofollow" class="external text" href="//arxiv.org/archive/cs.LG">cs.LG</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=On+the+Bias-Variance+Tradeoff%3A+Textbooks+Need+an+Update&amp;rft.date=2019&amp;rft_id=info%3Aarxiv%2F1912.08286&amp;rft.aulast=Neal&amp;rft.aufirst=Brady&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABias%E2%80%93variance+tradeoff" class="Z3988"></span></span>\n</li>\n<li id="cite_note-neal2018-5"><span class="mw-cite-backlink">^ <a href="#cite_ref-neal2018_5-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-neal2018_5-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r999302996"/><cite id="CITEREFNealMittalBaratinTantia2018" class="citation arxiv cs1">Neal, Brady; Mittal, Sarthak; Baratin, Aristide; Tantia, Vinayak; Scicluna, Matthew; Lacoste-Julien, Simon; Mitliagkas, Ioannis (2018). "A Modern Take on the Bias-Variance Tradeoff in Neural Networks". <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/1810.08591">1810.08591</a></span> [<a rel="nofollow" class="external text" href="//arxiv.org/archive/cs.LG">cs.LG</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=A+Modern+Take+on+the+Bias-Variance+Tradeoff+in+Neural+Networks&amp;rft.date=2018&amp;rft_id=info%3Aarxiv%2F1810.08591&amp;rft.aulast=Neal&amp;rft.aufirst=Brady&amp;rft.au=Mittal%2C+Sarthak&amp;rft.au=Baratin%2C+Aristide&amp;rft.au=Tantia%2C+Vinayak&amp;rft.au=Scicluna%2C+Matthew&amp;rft.au=Lacoste-Julien%2C+Simon&amp;rft.au=Mitliagkas%2C+Ioannis&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABias%E2%80%93variance+tradeoff" class="Z3988"></span></span>\n</li>\n<li id="cite_note-6"><span class="mw-cite-backlink"><b><a href="#cite_ref-6">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r999302996"/><cite id="CITEREFVapnik2000" class="citation book cs1">Vapnik, Vladimir (2000). <a rel="nofollow" class="external text" href="https://dx.doi.org/10.1007/978-1-4757-3264-1"><i>The nature of statistical learning theory</i></a>. New York: Springer-Verlag. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-1-4757-3264-1" title="Special:BookSources/978-1-4757-3264-1"><bdi>978-1-4757-3264-1</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+nature+of+statistical+learning+theory&amp;rft.place=New+York&amp;rft.pub=Springer-Verlag&amp;rft.date=2000&amp;rft.isbn=978-1-4757-3264-1&amp;rft.aulast=Vapnik&amp;rft.aufirst=Vladimir&amp;rft_id=https%3A%2F%2Fdx.doi.org%2F10.1007%2F978-1-4757-3264-1&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABias%E2%80%93variance+tradeoff" class="Z3988"></span></span>\n</li>\n<li id="cite_note-islr-7"><span class="mw-cite-backlink">^ <a href="#cite_ref-islr_7-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-islr_7-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-islr_7-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r999302996"/><cite id="CITEREFJamesWittenHastieTibshirani2013" class="citation book cs1">James, Gareth; <a href="/wiki/Daniela_Witten" title="Daniela Witten">Witten, Daniela</a>; <a href="/wiki/Trevor_Hastie" title="Trevor Hastie">Hastie, Trevor</a>; <a href="/wiki/Robert_Tibshirani" title="Robert Tibshirani">Tibshirani, Robert</a> (2013). <a rel="nofollow" class="external text" href="http://www-bcf.usc.edu/~gareth/ISL/"><i>An Introduction to Statistical Learning</i></a>. Springer.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=An+Introduction+to+Statistical+Learning&amp;rft.pub=Springer&amp;rft.date=2013&amp;rft.aulast=James&amp;rft.aufirst=Gareth&amp;rft.au=Witten%2C+Daniela&amp;rft.au=Hastie%2C+Trevor&amp;rft.au=Tibshirani%2C+Robert&amp;rft_id=http%3A%2F%2Fwww-bcf.usc.edu%2F~gareth%2FISL%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABias%E2%80%93variance+tradeoff" class="Z3988"></span></span>\n</li>\n<li id="cite_note-ESL-8"><span class="mw-cite-backlink">^ <a href="#cite_ref-ESL_8-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-ESL_8-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r999302996"/><cite id="CITEREFHastieTibshiraniFriedman2009" class="citation book cs1">Hastie, Trevor; Tibshirani, Robert; <a href="/wiki/Jerome_H._Friedman" title="Jerome H. Friedman">Friedman, Jerome H.</a> (2009). <a rel="nofollow" class="external text" href="https://web.archive.org/web/20150126123924/http://statweb.stanford.edu/~tibs/ElemStatLearn/"><i>The Elements of Statistical Learning</i></a>. Archived from <a rel="nofollow" class="external text" href="http://statweb.stanford.edu/~tibs/ElemStatLearn/">the original</a> on 2015-01-26<span class="reference-accessdate">. Retrieved <span class="nowrap">2014-08-20</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Elements+of+Statistical+Learning&amp;rft.date=2009&amp;rft.aulast=Hastie&amp;rft.aufirst=Trevor&amp;rft.au=Tibshirani%2C+Robert&amp;rft.au=Friedman%2C+Jerome+H.&amp;rft_id=http%3A%2F%2Fstatweb.stanford.edu%2F~tibs%2FElemStatLearn%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABias%E2%80%93variance+tradeoff" class="Z3988"></span></span>\n</li>\n<li id="cite_note-9"><span class="mw-cite-backlink"><b><a href="#cite_ref-9">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r999302996"/><cite id="CITEREFVijayakumar2007" class="citation web cs1"><a href="/wiki/Sethu_Vijayakumar" title="Sethu Vijayakumar">Vijayakumar, Sethu</a> (2007). <a rel="nofollow" class="external text" href="http://www.inf.ed.ac.uk/teaching/courses/mlsc/Notes/Lecture4/BiasVariance.pdf">"The Bias\xe2\x80\x93Variance Tradeoff"</a> <span class="cs1-format">(PDF)</span>. <a href="/wiki/University_of_Edinburgh" title="University of Edinburgh">University of Edinburgh</a><span class="reference-accessdate">. Retrieved <span class="nowrap">19 August</span> 2014</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=The+Bias%E2%80%93Variance+Tradeoff&amp;rft.pub=University+of+Edinburgh&amp;rft.date=2007&amp;rft.aulast=Vijayakumar&amp;rft.aufirst=Sethu&amp;rft_id=http%3A%2F%2Fwww.inf.ed.ac.uk%2Fteaching%2Fcourses%2Fmlsc%2FNotes%2FLecture4%2FBiasVariance.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABias%E2%80%93variance+tradeoff" class="Z3988"></span></span>\n</li>\n<li id="cite_note-10"><span class="mw-cite-backlink"><b><a href="#cite_ref-10">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r999302996"/><cite id="CITEREFShakhnarovich2011" class="citation web cs1">Shakhnarovich, Greg (2011). <a rel="nofollow" class="external text" href="https://web.archive.org/web/20140821063842/http://ttic.uchicago.edu/~gregory/courses/wis-ml2012/lectures/biasVarDecom.pdf">"Notes on derivation of bias-variance decomposition in linear regression"</a> <span class="cs1-format">(PDF)</span>. Archived from <a rel="nofollow" class="external text" href="http://ttic.uchicago.edu/~gregory/courses/wis-ml2012/lectures/biasVarDecom.pdf">the original</a> <span class="cs1-format">(PDF)</span> on 21 August 2014<span class="reference-accessdate">. Retrieved <span class="nowrap">20 August</span> 2014</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Notes+on+derivation+of+bias-variance+decomposition+in+linear+regression&amp;rft.date=2011&amp;rft.aulast=Shakhnarovich&amp;rft.aufirst=Greg&amp;rft_id=http%3A%2F%2Fttic.uchicago.edu%2F~gregory%2Fcourses%2Fwis-ml2012%2Flectures%2FbiasVarDecom.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABias%E2%80%93variance+tradeoff" class="Z3988"></span></span>\n</li>\n<li id="cite_note-11"><span class="mw-cite-backlink"><b><a href="#cite_ref-11">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r999302996"/><cite id="CITEREFBelsley1991" class="citation book cs1">Belsley, David (1991). <i>Conditioning diagnostics&#160;: collinearity and weak data in regression</i>. New York (NY): Wiley. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0471528890" title="Special:BookSources/978-0471528890"><bdi>978-0471528890</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Conditioning+diagnostics+%3A+collinearity+and+weak+data+in+regression&amp;rft.place=New+York+%28NY%29&amp;rft.pub=Wiley&amp;rft.date=1991&amp;rft.isbn=978-0471528890&amp;rft.aulast=Belsley&amp;rft.aufirst=David&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABias%E2%80%93variance+tradeoff" class="Z3988"></span></span>\n</li>\n<li id="cite_note-geman-12"><span class="mw-cite-backlink">^ <a href="#cite_ref-geman_12-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-geman_12-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-geman_12-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r999302996"/><cite id="CITEREFGemanBienenstockDoursat1992" class="citation journal cs1"><a href="/wiki/Stuart_Geman" title="Stuart Geman">Geman, Stuart</a>; Bienenstock, \xc3\x89lie; Doursat, Ren\xc3\xa9 (1992). <a rel="nofollow" class="external text" href="http://web.mit.edu/6.435/www/Geman92.pdf">"Neural networks and the bias/variance dilemma"</a> <span class="cs1-format">(PDF)</span>. <i>Neural Computation</i>. <b>4</b>: 1\xe2\x80\x9358. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1162%2Fneco.1992.4.1.1">10.1162/neco.1992.4.1.1</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Neural+Computation&amp;rft.atitle=Neural+networks+and+the+bias%2Fvariance+dilemma&amp;rft.volume=4&amp;rft.pages=1-58&amp;rft.date=1992&amp;rft_id=info%3Adoi%2F10.1162%2Fneco.1992.4.1.1&amp;rft.aulast=Geman&amp;rft.aufirst=Stuart&amp;rft.au=Bienenstock%2C+%C3%89lie&amp;rft.au=Doursat%2C+Ren%C3%A9&amp;rft_id=http%3A%2F%2Fweb.mit.edu%2F6.435%2Fwww%2FGeman92.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABias%E2%80%93variance+tradeoff" class="Z3988"></span></span>\n</li>\n<li id="cite_note-13"><span class="mw-cite-backlink"><b><a href="#cite_ref-13">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r999302996"/><cite id="CITEREFGagliardi2011" class="citation journal cs1">Gagliardi, Francesco (May 2011). <a rel="nofollow" class="external text" href="https://www.researchgate.net/publication/51173579">"Instance-based classifiers applied to medical databases: diagnosis and knowledge extraction"</a>. <i>Artificial Intelligence in Medicine</i>. <b>52</b> (3): 123\xe2\x80\x93139. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fj.artmed.2011.04.002">10.1016/j.artmed.2011.04.002</a>. <a href="/wiki/PMID_(identifier)" class="mw-redirect" title="PMID (identifier)">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/21621400">21621400</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Artificial+Intelligence+in+Medicine&amp;rft.atitle=Instance-based+classifiers+applied+to+medical+databases%3A+diagnosis+and+knowledge+extraction&amp;rft.volume=52&amp;rft.issue=3&amp;rft.pages=123-139&amp;rft.date=2011-05&amp;rft_id=info%3Adoi%2F10.1016%2Fj.artmed.2011.04.002&amp;rft_id=info%3Apmid%2F21621400&amp;rft.aulast=Gagliardi&amp;rft.aufirst=Francesco&amp;rft_id=https%3A%2F%2Fwww.researchgate.net%2Fpublication%2F51173579&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABias%E2%80%93variance+tradeoff" class="Z3988"></span></span>\n</li>\n<li id="cite_note-14"><span class="mw-cite-backlink"><b><a href="#cite_ref-14">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r999302996"/><cite id="CITEREFTingVijaykumarSchaal2011" class="citation book cs1">Ting, Jo-Anne; Vijaykumar, Sethu; Schaal, Stefan (2011). "Locally Weighted Regression for Control".  In Sammut, Claude; Webb, Geoffrey I. (eds.). <a rel="nofollow" class="external text" href="http://homepages.inf.ed.ac.uk/svijayak/publications/ting-EMLDM2016.pdf"><i>Encyclopedia of Machine Learning</i></a> <span class="cs1-format">(PDF)</span>. Springer. p.&#160;615. <a href="/wiki/Bibcode_(identifier)" class="mw-redirect" title="Bibcode (identifier)">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2010eoml.book.....S">2010eoml.book.....S</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Locally+Weighted+Regression+for+Control&amp;rft.btitle=Encyclopedia+of+Machine+Learning&amp;rft.pages=615&amp;rft.pub=Springer&amp;rft.date=2011&amp;rft_id=info%3Abibcode%2F2010eoml.book.....S&amp;rft.aulast=Ting&amp;rft.aufirst=Jo-Anne&amp;rft.au=Vijaykumar%2C+Sethu&amp;rft.au=Schaal%2C+Stefan&amp;rft_id=http%3A%2F%2Fhomepages.inf.ed.ac.uk%2Fsvijayak%2Fpublications%2Fting-EMLDM2016.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABias%E2%80%93variance+tradeoff" class="Z3988"></span></span>\n</li>\n<li id="cite_note-15"><span class="mw-cite-backlink"><b><a href="#cite_ref-15">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r999302996"/><cite id="CITEREFFortmann-Roe2012" class="citation web cs1">Fortmann-Roe, Scott (2012). <a rel="nofollow" class="external text" href="http://scott.fortmann-roe.com/docs/BiasVariance.html">"Understanding the Bias\xe2\x80\x93Variance Tradeoff"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Understanding+the+Bias%E2%80%93Variance+Tradeoff&amp;rft.date=2012&amp;rft.aulast=Fortmann-Roe&amp;rft.aufirst=Scott&amp;rft_id=http%3A%2F%2Fscott.fortmann-roe.com%2Fdocs%2FBiasVariance.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABias%E2%80%93variance+tradeoff" class="Z3988"></span></span>\n</li>\n<li id="cite_note-16"><span class="mw-cite-backlink"><b><a href="#cite_ref-16">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r999302996"/><cite id="CITEREFDomingos2000" class="citation conference cs1"><a href="/wiki/Pedro_Domingos" title="Pedro Domingos">Domingos, Pedro</a> (2000). <a rel="nofollow" class="external text" href="http://homes.cs.washington.edu/~pedrod/bvd.pdf"><i>A unified bias-variance decomposition</i></a> <span class="cs1-format">(PDF)</span>. ICML.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.btitle=A+unified+bias-variance+decomposition&amp;rft.date=2000&amp;rft.aulast=Domingos&amp;rft.aufirst=Pedro&amp;rft_id=http%3A%2F%2Fhomes.cs.washington.edu%2F~pedrod%2Fbvd.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABias%E2%80%93variance+tradeoff" class="Z3988"></span></span>\n</li>\n<li id="cite_note-17"><span class="mw-cite-backlink"><b><a href="#cite_ref-17">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r999302996"/><cite id="CITEREFValentiniDietterich2004" class="citation journal cs1">Valentini, Giorgio; <a href="/wiki/Thomas_G._Dietterich" title="Thomas G. Dietterich">Dietterich, Thomas G.</a> (2004). <a rel="nofollow" class="external text" href="http://www.jmlr.org/papers/volume5/valentini04a/valentini04a.pdf">"Bias\xe2\x80\x93variance analysis of support vector machines for the development of SVM-based ensemble methods"</a> <span class="cs1-format">(PDF)</span>. <i><a href="/wiki/Journal_of_Machine_Learning_Research" title="Journal of Machine Learning Research">Journal of Machine Learning Research</a></i>. <b>5</b>: 725\xe2\x80\x93775.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Machine+Learning+Research&amp;rft.atitle=Bias%E2%80%93variance+analysis+of+support+vector+machines+for+the+development+of+SVM-based+ensemble+methods&amp;rft.volume=5&amp;rft.pages=725-775&amp;rft.date=2004&amp;rft.aulast=Valentini&amp;rft.aufirst=Giorgio&amp;rft.au=Dietterich%2C+Thomas+G.&amp;rft_id=http%3A%2F%2Fwww.jmlr.org%2Fpapers%2Fvolume5%2Fvalentini04a%2Fvalentini04a.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABias%E2%80%93variance+tradeoff" class="Z3988"></span></span>\n</li>\n<li id="cite_note-18"><span class="mw-cite-backlink"><b><a href="#cite_ref-18">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r999302996"/><cite id="CITEREFManningRaghavanSch\xc3\xbctze2008" class="citation book cs1">Manning, Christopher D.; Raghavan, Prabhakar; Sch\xc3\xbctze, Hinrich (2008). <a rel="nofollow" class="external text" href="http://nlp.stanford.edu/IR-book/"><i>Introduction to Information Retrieval</i></a>. Cambridge University Press. pp.&#160;308\xe2\x80\x93314.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Introduction+to+Information+Retrieval&amp;rft.pages=308-314&amp;rft.pub=Cambridge+University+Press&amp;rft.date=2008&amp;rft.aulast=Manning&amp;rft.aufirst=Christopher+D.&amp;rft.au=Raghavan%2C+Prabhakar&amp;rft.au=Sch%C3%BCtze%2C+Hinrich&amp;rft_id=http%3A%2F%2Fnlp.stanford.edu%2FIR-book%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABias%E2%80%93variance+tradeoff" class="Z3988"></span></span>\n</li>\n<li id="cite_note-19"><span class="mw-cite-backlink"><b><a href="#cite_ref-19">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r999302996"/><cite id="CITEREFFrancois-LavetRabusseauPineauErnst2019" class="citation journal cs1">Francois-Lavet, Vincent; Rabusseau, Guillaume; Pineau, Joelle; Ernst, Damien; Fonteneau, Raphael (2019). <a rel="nofollow" class="external text" href="https://jair.org/index.php/jair/article/view/11478">"On Over\xef\xac\x81tting and Asymptotic Bias in Batch Reinforcement Learning with Partial Observability"</a>. <i>Journal of AI Research</i>. <b>65</b>: 1\xe2\x80\x9330. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1613%2Fjair.1.11478">10.1613/jair.1.11478</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+AI+Research&amp;rft.atitle=On+Over%EF%AC%81tting+and+Asymptotic+Bias+in+Batch+Reinforcement+Learning+with+Partial+Observability&amp;rft.volume=65&amp;rft.pages=1-30&amp;rft.date=2019&amp;rft_id=info%3Adoi%2F10.1613%2Fjair.1.11478&amp;rft.aulast=Francois-Lavet&amp;rft.aufirst=Vincent&amp;rft.au=Rabusseau%2C+Guillaume&amp;rft.au=Pineau%2C+Joelle&amp;rft.au=Ernst%2C+Damien&amp;rft.au=Fonteneau%2C+Raphael&amp;rft_id=https%3A%2F%2Fjair.org%2Findex.php%2Fjair%2Farticle%2Fview%2F11478&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABias%E2%80%93variance+tradeoff" class="Z3988"></span></span>\n</li>\n<li id="cite_note-ReferenceA-20"><span class="mw-cite-backlink"><b><a href="#cite_ref-ReferenceA_20-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r999302996"/><cite id="CITEREFGigerenzerBrighton2009" class="citation journal cs1"><a href="/wiki/Gerd_Gigerenzer" title="Gerd Gigerenzer">Gigerenzer, Gerd</a>; Brighton, Henry (2009). "Homo Heuristicus: Why Biased Minds Make Better Inferences". <i>Topics in Cognitive Science</i>. <b>1</b> (1): 107\xe2\x80\x93143. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1111%2Fj.1756-8765.2008.01006.x">10.1111/j.1756-8765.2008.01006.x</a>. <a href="/wiki/Hdl_(identifier)" class="mw-redirect" title="Hdl (identifier)">hdl</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//hdl.handle.net/11858%2F00-001M-0000-0024-F678-0">11858/00-001M-0000-0024-F678-0</a></span>. <a href="/wiki/PMID_(identifier)" class="mw-redirect" title="PMID (identifier)">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/25164802">25164802</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Topics+in+Cognitive+Science&amp;rft.atitle=Homo+Heuristicus%3A+Why+Biased+Minds+Make+Better+Inferences&amp;rft.volume=1&amp;rft.issue=1&amp;rft.pages=107-143&amp;rft.date=2009&amp;rft_id=info%3Ahdl%2F11858%2F00-001M-0000-0024-F678-0&amp;rft_id=info%3Apmid%2F25164802&amp;rft_id=info%3Adoi%2F10.1111%2Fj.1756-8765.2008.01006.x&amp;rft.aulast=Gigerenzer&amp;rft.aufirst=Gerd&amp;rft.au=Brighton%2C+Henry&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ABias%E2%80%93variance+tradeoff" class="Z3988"></span></span>\n</li>\n</ol></div></div>\n<!-- \nNewPP limit report\nParsed by mw1413\nCached time: 20210125201053\nCache expiry: 2592000\nDynamic content: false\nComplications: [vary\xe2\x80\x90revision\xe2\x80\x90sha1]\nCPU time usage: 0.492 seconds\nReal time usage: 1.093 seconds\nPreprocessor visited node count: 1974/1000000\nPost\xe2\x80\x90expand include size: 66248/2097152 bytes\nTemplate argument size: 1280/2097152 bytes\nHighest expansion depth: 13/40\nExpensive parser function count: 0/500\nUnstrip recursion depth: 1/20\nUnstrip post\xe2\x80\x90expand size: 72261/5000000 bytes\nLua time usage: 0.234/10.000 seconds\nLua memory usage: 5201581/52428800 bytes\nNumber of Wikibase entities loaded: 0/400\n-->\n<!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%  500.186      1 -total\n 45.77%  228.947      1 Template:Reflist\n 27.29%  136.491      1 Template:Machine_learning_bar\n 26.49%  132.481      1 Template:Sidebar_with_collapsible_lists\n 24.81%  124.097      7 Template:Cite_journal\n  7.75%   38.770      1 Template:Div_col\n  7.16%   35.829      1 Template:Longitem\n  6.93%   34.684      6 Template:Cite_book\n  6.44%   32.236      1 Template:Nobold\n  5.20%   26.018      5 Template:Rp\n-->\n\n<!-- Saved in parser cache with key enwiki:pcache:idhash:40678189-0!canonical!math=5 and timestamp 20210125201052 and revision id 996197234. Serialized with JSON.\n -->\n</div><noscript><img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" /></noscript>\n<div class="printfooter">Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Bias\xe2\x80\x93variance_tradeoff&amp;oldid=996197234">https://en.wikipedia.org/w/index.php?title=Bias\xe2\x80\x93variance_tradeoff&amp;oldid=996197234</a>"</div></div>\n\t\t<div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="/wiki/Category:Dilemmas" title="Category:Dilemmas">Dilemmas</a></li><li><a href="/wiki/Category:Model_selection" title="Category:Model selection">Model selection</a></li><li><a href="/wiki/Category:Machine_learning" title="Category:Machine learning">Machine learning</a></li><li><a href="/wiki/Category:Statistical_classification" title="Category:Statistical classification">Statistical classification</a></li></ul></div></div>\n\t</div>\n</div>\n<div id=\'mw-data-after-content\'>\n\t<div class="read-more-container"></div>\n</div>\n\n<div id="mw-navigation">\n\t<h2>Navigation menu</h2>\n\t<div id="mw-head">\n\t\t<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav id="p-personal" class="mw-portlet mw-portlet-personal vector-menu" aria-labelledby="p-personal-label" role="navigation" \n\t >\n\t<h3 id="p-personal-label">\n\t\t<span>Personal tools</span>\n\t</h3>\n\t<div class="vector-menu-content">\n\t\t<ul class="vector-menu-content-list"><li id="pt-anonuserpage">Not logged in</li><li id="pt-anontalk"><a href="/wiki/Special:MyTalk" title="Discussion about edits from this IP address [n]" accesskey="n">Talk</a></li><li id="pt-anoncontribs"><a href="/wiki/Special:MyContributions" title="A list of edits made from this IP address [y]" accesskey="y">Contributions</a></li><li id="pt-createaccount"><a href="/w/index.php?title=Special:CreateAccount&amp;returnto=Bias%E2%80%93variance+tradeoff" title="You are encouraged to create an account and log in; however, it is not mandatory">Create account</a></li><li id="pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Bias%E2%80%93variance+tradeoff" title="You&#039;re encouraged to log in; however, it&#039;s not mandatory. [o]" accesskey="o">Log in</a></li></ul>\n\t\t\n\t</div>\n</nav>\n\n\t\t<div id="left-navigation">\n\t\t\t<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav id="p-namespaces" class="mw-portlet mw-portlet-namespaces vector-menu vector-menu-tabs" aria-labelledby="p-namespaces-label" role="navigation" \n\t >\n\t<h3 id="p-namespaces-label">\n\t\t<span>Namespaces</span>\n\t</h3>\n\t<div class="vector-menu-content">\n\t\t<ul class="vector-menu-content-list"><li id="ca-nstab-main" class="selected"><a href="/wiki/Bias%E2%80%93variance_tradeoff" title="View the content page [c]" accesskey="c">Article</a></li><li id="ca-talk"><a href="/wiki/Talk:Bias%E2%80%93variance_tradeoff" rel="discussion" title="Discuss improvements to the content page [t]" accesskey="t">Talk</a></li></ul>\n\t\t\n\t</div>\n</nav>\n\n\t\t\t<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav id="p-variants" class="mw-portlet mw-portlet-variants emptyPortlet vector-menu vector-menu-dropdown" aria-labelledby="p-variants-label" role="navigation" \n\t >\n\t<input type="checkbox" class="vector-menu-checkbox" aria-labelledby="p-variants-label" />\n\t<h3 id="p-variants-label">\n\t\t<span>Variants</span>\n\t</h3>\n\t<div class="vector-menu-content">\n\t\t<ul class="vector-menu-content-list"></ul>\n\t\t\n\t</div>\n</nav>\n\n\t\t</div>\n\t\t<div id="right-navigation">\n\t\t\t<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav id="p-views" class="mw-portlet mw-portlet-views vector-menu vector-menu-tabs" aria-labelledby="p-views-label" role="navigation" \n\t >\n\t<h3 id="p-views-label">\n\t\t<span>Views</span>\n\t</h3>\n\t<div class="vector-menu-content">\n\t\t<ul class="vector-menu-content-list"><li id="ca-view" class="selected"><a href="/wiki/Bias%E2%80%93variance_tradeoff">Read</a></li><li id="ca-edit"><a href="/w/index.php?title=Bias%E2%80%93variance_tradeoff&amp;action=edit" title="Edit this page [e]" accesskey="e">Edit</a></li><li id="ca-history"><a href="/w/index.php?title=Bias%E2%80%93variance_tradeoff&amp;action=history" title="Past revisions of this page [h]" accesskey="h">View history</a></li></ul>\n\t\t\n\t</div>\n</nav>\n\n\t\t\t<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav id="p-cactions" class="mw-portlet mw-portlet-cactions emptyPortlet vector-menu vector-menu-dropdown" aria-labelledby="p-cactions-label" role="navigation" \n\t >\n\t<input type="checkbox" class="vector-menu-checkbox" aria-labelledby="p-cactions-label" />\n\t<h3 id="p-cactions-label">\n\t\t<span>More</span>\n\t</h3>\n\t<div class="vector-menu-content">\n\t\t<ul class="vector-menu-content-list"></ul>\n\t\t\n\t</div>\n</nav>\n\n\t\t\t<div id="p-search" role="search">\n\t<h3 >\n\t\t<label for="searchInput">Search</label>\n\t</h3>\n\t<form action="/w/index.php" id="searchform">\n\t\t<div id="simpleSearch" data-search-loc="header-navigation">\n\t\t\t<input type="search" name="search" placeholder="Search Wikipedia" autocapitalize="sentences" title="Search Wikipedia [f]" accesskey="f" id="searchInput"/>\n\t\t\t<input type="hidden" name="title" value="Special:Search">\n\t\t\t<input type="submit" name="fulltext" value="Search" title="Search Wikipedia for this text" id="mw-searchButton" class="searchButton mw-fallbackSearchButton"/>\n\t\t\t<input type="submit" name="go" value="Go" title="Go to a page with this exact name if it exists" id="searchButton" class="searchButton"/>\n\t\t</div>\n\t</form>\n</div>\n\n\t\t</div>\n\t</div>\n\t\n<div id="mw-panel">\n\t<div id="p-logo" role="banner">\n\t\t<a class="mw-wiki-logo" href="/wiki/Main_Page"\n\t\t\ttitle="Visit the main page"></a>\n\t</div>\n\t<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav id="p-navigation" class="mw-portlet mw-portlet-navigation vector-menu vector-menu-portal portal" aria-labelledby="p-navigation-label" role="navigation" \n\t >\n\t<h3 id="p-navigation-label">\n\t\t<span>Navigation</span>\n\t</h3>\n\t<div class="vector-menu-content">\n\t\t<ul class="vector-menu-content-list"><li id="n-mainpage-description"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li><li id="n-contents"><a href="/wiki/Wikipedia:Contents" title="Guides to browsing Wikipedia">Contents</a></li><li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Articles related to current events">Current events</a></li><li id="n-randompage"><a href="/wiki/Special:Random" title="Visit a randomly selected article [x]" accesskey="x">Random article</a></li><li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Learn about Wikipedia and how it works">About Wikipedia</a></li><li id="n-contactpage"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact us</a></li><li id="n-sitesupport"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us by donating to the Wikimedia Foundation">Donate</a></li></ul>\n\t\t\n\t</div>\n</nav>\n\n\t<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav id="p-interaction" class="mw-portlet mw-portlet-interaction vector-menu vector-menu-portal portal" aria-labelledby="p-interaction-label" role="navigation" \n\t >\n\t<h3 id="p-interaction-label">\n\t\t<span>Contribute</span>\n\t</h3>\n\t<div class="vector-menu-content">\n\t\t<ul class="vector-menu-content-list"><li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li><li id="n-introduction"><a href="/wiki/Help:Introduction" title="Learn how to edit Wikipedia">Learn to edit</a></li><li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="The hub for editors">Community portal</a></li><li id="n-recentchanges"><a href="/wiki/Special:RecentChanges" title="A list of recent changes to Wikipedia [r]" accesskey="r">Recent changes</a></li><li id="n-upload"><a href="/wiki/Wikipedia:File_Upload_Wizard" title="Add images or other media for use on Wikipedia">Upload file</a></li></ul>\n\t\t\n\t</div>\n</nav>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav id="p-tb" class="mw-portlet mw-portlet-tb vector-menu vector-menu-portal portal" aria-labelledby="p-tb-label" role="navigation" \n\t >\n\t<h3 id="p-tb-label">\n\t\t<span>Tools</span>\n\t</h3>\n\t<div class="vector-menu-content">\n\t\t<ul class="vector-menu-content-list"><li id="t-whatlinkshere"><a href="/wiki/Special:WhatLinksHere/Bias%E2%80%93variance_tradeoff" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j">What links here</a></li><li id="t-recentchangeslinked"><a href="/wiki/Special:RecentChangesLinked/Bias%E2%80%93variance_tradeoff" rel="nofollow" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li><li id="t-upload"><a href="/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [u]" accesskey="u">Upload file</a></li><li id="t-specialpages"><a href="/wiki/Special:SpecialPages" title="A list of all special pages [q]" accesskey="q">Special pages</a></li><li id="t-permalink"><a href="/w/index.php?title=Bias%E2%80%93variance_tradeoff&amp;oldid=996197234" title="Permanent link to this revision of this page">Permanent link</a></li><li id="t-info"><a href="/w/index.php?title=Bias%E2%80%93variance_tradeoff&amp;action=info" title="More information about this page">Page information</a></li><li id="t-cite"><a href="/w/index.php?title=Special:CiteThisPage&amp;page=Bias%E2%80%93variance_tradeoff&amp;id=996197234&amp;wpFormIdentifier=titleform" title="Information on how to cite this page">Cite this page</a></li><li id="t-wikibase"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q17003119" title="Structured data on this page hosted by Wikidata [g]" accesskey="g">Wikidata item</a></li></ul>\n\t\t\n\t</div>\n</nav>\n<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav id="p-coll-print_export" class="mw-portlet mw-portlet-coll-print_export vector-menu vector-menu-portal portal" aria-labelledby="p-coll-print_export-label" role="navigation" \n\t >\n\t<h3 id="p-coll-print_export-label">\n\t\t<span>Print/export</span>\n\t</h3>\n\t<div class="vector-menu-content">\n\t\t<ul class="vector-menu-content-list"><li id="coll-download-as-rl"><a href="/w/index.php?title=Special:DownloadAsPdf&amp;page=Bias%E2%80%93variance_tradeoff&amp;action=show-download-screen" title="Download this page as a PDF file">Download as PDF</a></li><li id="t-print"><a href="/w/index.php?title=Bias%E2%80%93variance_tradeoff&amp;printable=yes" title="Printable version of this page [p]" accesskey="p">Printable version</a></li></ul>\n\t\t\n\t</div>\n</nav>\n\n\t<!-- Please do not use role attribute as CSS selector, it is deprecated. -->\n<nav id="p-lang" class="mw-portlet mw-portlet-lang vector-menu vector-menu-portal portal" aria-labelledby="p-lang-label" role="navigation" \n\t >\n\t<h3 id="p-lang-label">\n\t\t<span>Languages</span>\n\t</h3>\n\t<div class="vector-menu-content">\n\t\t<ul class="vector-menu-content-list"><li class="interlanguage-link interwiki-de"><a href="https://de.wikipedia.org/wiki/Verzerrung-Varianz-Dilemma" title="Verzerrung-Varianz-Dilemma \xe2\x80\x93 German" lang="de" hreflang="de" class="interlanguage-link-target">Deutsch</a></li><li class="interlanguage-link interwiki-fr"><a href="https://fr.wikipedia.org/wiki/Dilemme_biais-variance" title="Dilemme biais-variance \xe2\x80\x93 French" lang="fr" hreflang="fr" class="interlanguage-link-target">Fran\xc3\xa7ais</a></li><li class="interlanguage-link interwiki-ko"><a href="https://ko.wikipedia.org/wiki/%ED%8E%B8%ED%96%A5-%EB%B6%84%EC%82%B0_%ED%8A%B8%EB%A0%88%EC%9D%B4%EB%93%9C%EC%98%A4%ED%94%84" title="\xed\x8e\xb8\xed\x96\xa5-\xeb\xb6\x84\xec\x82\xb0 \xed\x8a\xb8\xeb\xa0\x88\xec\x9d\xb4\xeb\x93\x9c\xec\x98\xa4\xed\x94\x84 \xe2\x80\x93 Korean" lang="ko" hreflang="ko" class="interlanguage-link-target">\xed\x95\x9c\xea\xb5\xad\xec\x96\xb4</a></li><li class="interlanguage-link interwiki-ja"><a href="https://ja.wikipedia.org/wiki/%E5%81%8F%E3%82%8A%E3%81%A8%E5%88%86%E6%95%A3" title="\xe5\x81\x8f\xe3\x82\x8a\xe3\x81\xa8\xe5\x88\x86\xe6\x95\xa3 \xe2\x80\x93 Japanese" lang="ja" hreflang="ja" class="interlanguage-link-target">\xe6\x97\xa5\xe6\x9c\xac\xe8\xaa\x9e</a></li><li class="interlanguage-link interwiki-pl"><a href="https://pl.wikipedia.org/wiki/Kompromis_mi%C4%99dzy_obci%C4%85%C5%BCeniem_a_wariancj%C4%85" title="Kompromis mi\xc4\x99dzy obci\xc4\x85\xc5\xbceniem a wariancj\xc4\x85 \xe2\x80\x93 Polish" lang="pl" hreflang="pl" class="interlanguage-link-target">Polski</a></li><li class="interlanguage-link interwiki-ru"><a href="https://ru.wikipedia.org/wiki/%D0%94%D0%B8%D0%BB%D0%B5%D0%BC%D0%BC%D0%B0_%D1%81%D0%BC%D0%B5%D1%89%D0%B5%D0%BD%D0%B8%D1%8F%E2%80%93%D0%B4%D0%B8%D1%81%D0%BF%D0%B5%D1%80%D1%81%D0%B8%D0%B8" title="\xd0\x94\xd0\xb8\xd0\xbb\xd0\xb5\xd0\xbc\xd0\xbc\xd0\xb0 \xd1\x81\xd0\xbc\xd0\xb5\xd1\x89\xd0\xb5\xd0\xbd\xd0\xb8\xd1\x8f\xe2\x80\x93\xd0\xb4\xd0\xb8\xd1\x81\xd0\xbf\xd0\xb5\xd1\x80\xd1\x81\xd0\xb8\xd0\xb8 \xe2\x80\x93 Russian" lang="ru" hreflang="ru" class="interlanguage-link-target">\xd0\xa0\xd1\x83\xd1\x81\xd1\x81\xd0\xba\xd0\xb8\xd0\xb9</a></li><li class="interlanguage-link interwiki-uk"><a href="https://uk.wikipedia.org/wiki/%D0%9A%D0%BE%D0%BC%D0%BF%D1%80%D0%BE%D0%BC%D1%96%D1%81_%D0%B7%D1%81%D1%83%D0%B2%D1%83_%D1%82%D0%B0_%D0%B4%D0%B8%D1%81%D0%BF%D0%B5%D1%80%D1%81%D1%96%D1%97" title="\xd0\x9a\xd0\xbe\xd0\xbc\xd0\xbf\xd1\x80\xd0\xbe\xd0\xbc\xd1\x96\xd1\x81 \xd0\xb7\xd1\x81\xd1\x83\xd0\xb2\xd1\x83 \xd1\x82\xd0\xb0 \xd0\xb4\xd0\xb8\xd1\x81\xd0\xbf\xd0\xb5\xd1\x80\xd1\x81\xd1\x96\xd1\x97 \xe2\x80\x93 Ukrainian" lang="uk" hreflang="uk" class="interlanguage-link-target">\xd0\xa3\xd0\xba\xd1\x80\xd0\xb0\xd1\x97\xd0\xbd\xd1\x81\xd1\x8c\xd0\xba\xd0\xb0</a></li></ul>\n\t\t<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q17003119#sitelinks-wikipedia" title="Edit interlanguage links" class="wbc-editpage">Edit links</a></span></div>\n\t</div>\n</nav>\n\n</div>\n\n</div>\n<footer id="footer" class="mw-footer" role="contentinfo" >\n\t<ul id="footer-info" >\n\t<li id="footer-info-lastmod"> This page was last edited on 25 December 2020, at 02:25<span class="anonymous-show">&#160;(UTC)</span>.</li>\n\t<li id="footer-info-copyright">Text is available under the <a rel="license" href="//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License">Creative Commons Attribution-ShareAlike License</a><a rel="license" href="//creativecommons.org/licenses/by-sa/3.0/" style="display:none;"></a>;\nadditional terms may apply.  By using this site, you agree to the <a href="//foundation.wikimedia.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="//foundation.wikimedia.org/wiki/Privacy_policy">Privacy Policy</a>. Wikipedia\xc2\xae is a registered trademark of the <a href="//www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>\n</ul>\n\n\t<ul id="footer-places" >\n\t<li id="footer-places-privacy"><a href="https://foundation.wikimedia.org/wiki/Privacy_policy" class="extiw" title="wmf:Privacy policy">Privacy policy</a></li>\n\t<li id="footer-places-about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>\n\t<li id="footer-places-disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>\n\t<li id="footer-places-contact"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>\n\t<li id="footer-places-mobileview"><a href="//en.m.wikipedia.org/w/index.php?title=Bias%E2%80%93variance_tradeoff&amp;mobileaction=toggle_view_mobile" class="noprint stopMobileRedirectToggle">Mobile view</a></li>\n\t<li id="footer-places-developers"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Developers</a></li>\n\t<li id="footer-places-statslink"><a href="https://stats.wikimedia.org/#/en.wikipedia.org">Statistics</a></li>\n\t<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Cookie_statement">Cookie statement</a></li>\n</ul>\n\n\t<ul id="footer-icons" class="noprint">\n\t<li id="footer-copyrightico"><a href="https://wikimediafoundation.org/"><img src="/static/images/footer/wikimedia-button.png" srcset="/static/images/footer/wikimedia-button-1.5x.png 1.5x, /static/images/footer/wikimedia-button-2x.png 2x" width="88" height="31" alt="Wikimedia Foundation" loading="lazy" /></a></li>\n\t<li id="footer-poweredbyico"><a href="https://www.mediawiki.org/"><img src="/static/images/footer/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" srcset="/static/images/footer/poweredby_mediawiki_132x47.png 1.5x, /static/images/footer/poweredby_mediawiki_176x62.png 2x" width="88" height="31" loading="lazy"/></a></li>\n</ul>\n\n\t<div style="clear: both;"></div>\n</footer>\n\n\n<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"0.492","walltime":"1.093","ppvisitednodes":{"value":1974,"limit":1000000},"postexpandincludesize":{"value":66248,"limit":2097152},"templateargumentsize":{"value":1280,"limit":2097152},"expansiondepth":{"value":13,"limit":40},"expensivefunctioncount":{"value":0,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":72261,"limit":5000000},"entityaccesscount":{"value":0,"limit":400},"timingprofile":["100.00%  500.186      1 -total"," 45.77%  228.947      1 Template:Reflist"," 27.29%  136.491      1 Template:Machine_learning_bar"," 26.49%  132.481      1 Template:Sidebar_with_collapsible_lists"," 24.81%  124.097      7 Template:Cite_journal","  7.75%   38.770      1 Template:Div_col","  7.16%   35.829      1 Template:Longitem","  6.93%   34.684      6 Template:Cite_book","  6.44%   32.236      1 Template:Nobold","  5.20%   26.018      5 Template:Rp"]},"scribunto":{"limitreport-timeusage":{"value":"0.234","limit":"10.000"},"limitreport-memusage":{"value":5201581,"limit":52428800}},"cachereport":{"origin":"mw1413","timestamp":"20210125201053","ttl":2592000,"transientcontent":false}}});});</script>\n<script type="application/ld+json">{"@context":"https:\\/\\/schema.org","@type":"Article","name":"Bias\\u2013variance tradeoff","url":"https:\\/\\/en.wikipedia.org\\/wiki\\/Bias%E2%80%93variance_tradeoff","sameAs":"http:\\/\\/www.wikidata.org\\/entity\\/Q17003119","mainEntity":"http:\\/\\/www.wikidata.org\\/entity\\/Q17003119","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\\/\\/www.wikimedia.org\\/static\\/images\\/wmf-hor-googpub.png"}},"datePublished":"2013-10-01T13:44:23Z","dateModified":"2020-12-25T02:25:45Z","image":"https:\\/\\/upload.wikimedia.org\\/wikipedia\\/commons\\/6\\/64\\/Test_function_and_noisy_data.png","headline":"property of a set of predictive models whereby models with a lower bias in parameter estimation have a higher variance of the parameter estimates across samples, and vice versa"}</script>\n<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":127,"wgHostname":"mw1367"});});</script>\n</body></html>'