{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "\n",
    "Lesson Goals\n",
    "\n",
    "    Examine data for potential issues.\n",
    "    Identify and fill in missing values.\n",
    "    Identify and correct incorrect values.\n",
    "    Remove low variance columns.\n",
    "    Identify potential outliers.\n",
    "    Correct incorrect data types.\n",
    "    Remove special characters and clean categorical variables.\n",
    "    Identify and remove duplicate records.\n",
    "\n",
    "Introduction\n",
    "\n",
    "When working with data sets, you will find that they often require a bit of cleaning. Whether Pandas originally read the data types incorrectly, records are duplicated, the data contains special characters or missing value, or there are slightly different references to the same entity, every data analyst must know how to clean the data they are working with before analyzing it. In this lesson, you will learn about some of the most common problems that make data messy and methods for correcting those problems and cleaning your data.\n",
    "\n",
    "The data set we are going to be using for this lesson is a messy version of the vehicles data set we worked with in the previous lesson. Let's import this version of our data set so that we can then practice cleaning it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (70,71,72,73,74,76,79) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('vehicles_messy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining Data for Potential Issues\n",
    "\n",
    "One of the first things we want to do is examine the data and look for any potential issues. Some of the things we are interested in identifying in the data at this stage include:\n",
    "\n",
    "    Missing values\n",
    "    Special characters\n",
    "    Incorrect values\n",
    "    Extreme values or outliers\n",
    "    Duplicate records\n",
    "    Incorrect data types\n",
    "\n",
    "The presence of these may cause problems when it's time to analyze the data, so we want to make sure we address them beforehand. We can start by visually inspecting the data using the head method, which will show us the first 5 rows of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>barrels08</th>\n",
       "      <th>barrelsA08</th>\n",
       "      <th>charge120</th>\n",
       "      <th>charge240</th>\n",
       "      <th>city08</th>\n",
       "      <th>city08U</th>\n",
       "      <th>cityA08</th>\n",
       "      <th>cityA08U</th>\n",
       "      <th>cityCD</th>\n",
       "      <th>cityE</th>\n",
       "      <th>...</th>\n",
       "      <th>mfrCode</th>\n",
       "      <th>c240Dscr</th>\n",
       "      <th>charge240b</th>\n",
       "      <th>c240bDscr</th>\n",
       "      <th>createdOn</th>\n",
       "      <th>modifiedOn</th>\n",
       "      <th>startStop</th>\n",
       "      <th>phevCity</th>\n",
       "      <th>phevHwy</th>\n",
       "      <th>phevComb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.695714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.964545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.207778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.964545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.347895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   barrels08  barrelsA08  charge120  charge240  city08  city08U  cityA08  \\\n",
       "0  15.695714         0.0        0.0        0.0      19      0.0        0   \n",
       "1  29.964545         0.0        0.0        0.0       9      0.0        0   \n",
       "2  12.207778         0.0        0.0        0.0      23      0.0        0   \n",
       "3  29.964545         0.0        0.0        0.0      10      0.0        0   \n",
       "4  17.347895         0.0        0.0        0.0      17      0.0        0   \n",
       "\n",
       "   cityA08U  cityCD  cityE  ...  mfrCode  c240Dscr  charge240b  c240bDscr  \\\n",
       "0       0.0     0.0    0.0  ...      NaN       NaN         0.0        NaN   \n",
       "1       0.0     0.0    0.0  ...      NaN       NaN         0.0        NaN   \n",
       "2       0.0     0.0    0.0  ...      NaN       NaN         0.0        NaN   \n",
       "3       0.0     0.0    0.0  ...      NaN       NaN         0.0        NaN   \n",
       "4       0.0     0.0    0.0  ...      NaN       NaN         0.0        NaN   \n",
       "\n",
       "                      createdOn                    modifiedOn  startStop  \\\n",
       "0  Tue Jan 01 00:00:00 EST 2013  Tue Jan 01 00:00:00 EST 2013        NaN   \n",
       "1  Tue Jan 01 00:00:00 EST 2013  Tue Jan 01 00:00:00 EST 2013        NaN   \n",
       "2  Tue Jan 01 00:00:00 EST 2013  Tue Jan 01 00:00:00 EST 2013        NaN   \n",
       "3  Tue Jan 01 00:00:00 EST 2013  Tue Jan 01 00:00:00 EST 2013        NaN   \n",
       "4  Tue Jan 01 00:00:00 EST 2013  Tue Jan 01 00:00:00 EST 2013        NaN   \n",
       "\n",
       "   phevCity  phevHwy  phevComb  \n",
       "0         0        0         0  \n",
       "1         0        0         0  \n",
       "2         0        0         0  \n",
       "3         0        0         0  \n",
       "4         0        0         0  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values\n",
    "\n",
    "From this initial view, we can see that our data set contains some columns that have missing values in them and others that seem to have a lot of zero values. Let's see how prevalent missing values are in our data. We can use the Pandas isnull method to check whether the value in each field is missing (null) and return either True or False for each field. We can use the sum method to total up the number of True values by column, and then we can add a condition using square brackets that will filter the data and show us only columns where the number of null values were greater than zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cylinders       123\n",
       "displ           120\n",
       "drive          1189\n",
       "eng_dscr      15403\n",
       "trany            11\n",
       "guzzler       35562\n",
       "trans_dscr    22796\n",
       "tCharger      32657\n",
       "sCharger      37177\n",
       "atvType       34771\n",
       "fuelType2     36435\n",
       "rangeA        36440\n",
       "evMotor       37281\n",
       "mfrCode       30818\n",
       "c240Dscr      37806\n",
       "c240bDscr     37807\n",
       "startStop     31705\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_cols = data.isnull().sum()\n",
    "null_cols[null_cols > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(null_cols)\n",
    "n = list(null_cols.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that some columns have relatively few null values while others have tens of thousands of nulls. For fields that have a lot of null values, you will often have to make a judgement call. If you don't think the information is going to be very useful to your analysis, then you would remove those columns from your data frame. In Pandas, we can do that using the drop method. For our purposes, let's remove the columns that have more than 10,000 null values in them. We will add these column names to a list, and then we will pass those columns to the drop method and indicate that we want columns (not rows) dropped by setting the axis parameter to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = list(null_cols[null_cols > 10000].index)\n",
    "data = data.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>barrels08</th>\n",
       "      <th>barrelsA08</th>\n",
       "      <th>charge120</th>\n",
       "      <th>charge240</th>\n",
       "      <th>city08</th>\n",
       "      <th>city08U</th>\n",
       "      <th>cityA08</th>\n",
       "      <th>cityA08U</th>\n",
       "      <th>cityCD</th>\n",
       "      <th>cityE</th>\n",
       "      <th>...</th>\n",
       "      <th>UHighwayA</th>\n",
       "      <th>VClass</th>\n",
       "      <th>year</th>\n",
       "      <th>youSaveSpend</th>\n",
       "      <th>charge240b</th>\n",
       "      <th>createdOn</th>\n",
       "      <th>modifiedOn</th>\n",
       "      <th>phevCity</th>\n",
       "      <th>phevHwy</th>\n",
       "      <th>phevComb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.695714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Two Seaters</td>\n",
       "      <td>1985</td>\n",
       "      <td>-1250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.964545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Two Seaters</td>\n",
       "      <td>1985</td>\n",
       "      <td>-8500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.207778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Subcompact Cars</td>\n",
       "      <td>1985</td>\n",
       "      <td>500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.964545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Vans</td>\n",
       "      <td>1985</td>\n",
       "      <td>-8500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.347895</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Compact Cars</td>\n",
       "      <td>1993</td>\n",
       "      <td>-4000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   barrels08  barrelsA08  charge120  charge240  city08  city08U  cityA08  \\\n",
       "0  15.695714         0.0        0.0        0.0      19      0.0        0   \n",
       "1  29.964545         0.0        0.0        0.0       9      0.0        0   \n",
       "2  12.207778         0.0        0.0        0.0      23      0.0        0   \n",
       "3  29.964545         0.0        0.0        0.0      10      0.0        0   \n",
       "4  17.347895         0.0        0.0        0.0      17      0.0        0   \n",
       "\n",
       "   cityA08U  cityCD  cityE  ...  UHighwayA           VClass  year  \\\n",
       "0       0.0     0.0    0.0  ...        0.0      Two Seaters  1985   \n",
       "1       0.0     0.0    0.0  ...        0.0      Two Seaters  1985   \n",
       "2       0.0     0.0    0.0  ...        0.0  Subcompact Cars  1985   \n",
       "3       0.0     0.0    0.0  ...        0.0             Vans  1985   \n",
       "4       0.0     0.0    0.0  ...        0.0     Compact Cars  1993   \n",
       "\n",
       "   youSaveSpend  charge240b                     createdOn  \\\n",
       "0         -1250         0.0  Tue Jan 01 00:00:00 EST 2013   \n",
       "1         -8500         0.0  Tue Jan 01 00:00:00 EST 2013   \n",
       "2           500         0.0  Tue Jan 01 00:00:00 EST 2013   \n",
       "3         -8500         0.0  Tue Jan 01 00:00:00 EST 2013   \n",
       "4         -4000         0.0  Tue Jan 01 00:00:00 EST 2013   \n",
       "\n",
       "                     modifiedOn  phevCity  phevHwy  phevComb  \n",
       "0  Tue Jan 01 00:00:00 EST 2013         0        0         0  \n",
       "1  Tue Jan 01 00:00:00 EST 2013         0        0         0  \n",
       "2  Tue Jan 01 00:00:00 EST 2013         0        0         0  \n",
       "3  Tue Jan 01 00:00:00 EST 2013         0        0         0  \n",
       "4  Tue Jan 01 00:00:00 EST 2013         0        0         0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This leaves us with just a handful of remaining columns that have null values. Of the columns that remain, it looks like the cylinders column and the displ column have a similar number of nulls. Perhaps they are missing for similar reasons. We can investigate this by subsetting the data set and looking at just the records where displ is null and just the columns we think will be informative in allowing us to determine a reason. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>trany</th>\n",
       "      <th>drive</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7138</th>\n",
       "      <td>2000</td>\n",
       "      <td>Nissan</td>\n",
       "      <td>Altra EV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7139</th>\n",
       "      <td>2000</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>RAV4 EV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2-Wheel Drive</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8143</th>\n",
       "      <td>2001</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>RAV4 EV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2-Wheel Drive</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8144</th>\n",
       "      <td>2001</td>\n",
       "      <td>Ford</td>\n",
       "      <td>Th!nk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8146</th>\n",
       "      <td>2001</td>\n",
       "      <td>Ford</td>\n",
       "      <td>Explorer USPS Electric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2-Wheel Drive</td>\n",
       "      <td>Electricity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year    make                   model trany          drive     fuelType  \\\n",
       "7138  2000  Nissan                Altra EV   NaN            NaN  Electricity   \n",
       "7139  2000  Toyota                 RAV4 EV   NaN  2-Wheel Drive  Electricity   \n",
       "8143  2001  Toyota                 RAV4 EV   NaN  2-Wheel Drive  Electricity   \n",
       "8144  2001    Ford                   Th!nk   NaN            NaN  Electricity   \n",
       "8146  2001    Ford  Explorer USPS Electric   NaN  2-Wheel Drive  Electricity   \n",
       "\n",
       "      cylinders  displ  \n",
       "7138        NaN    NaN  \n",
       "7139        NaN    NaN  \n",
       "8143        NaN    NaN  \n",
       "8144        NaN    NaN  \n",
       "8146        NaN    NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_displ = data[(data['displ'].isnull()==True)]\n",
    "null_displ = null_displ[['year', 'make', 'model', 'trany', 'drive','fuelType','cylinders', 'displ']]\n",
    "null_displ.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most of the time, cylinders is null when displ is null and that the most of the records where both fields are null have a fuel type of Electricity. This makes sense, as electric cars do not have cylinders and can therefore not have any displacement. In this case, it would make sense to replace these null values with zeros. Pandas makes it easy to do that with the fillna method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['displ', 'cylinders']] = data[['displ', 'cylinders']].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we filled the nulls in with zeros, but there are other strategies for filling in nulls. Depending on the circumstances, you might want to replace nulls with the column mean or mode values. Once you get more advanced, you can even use a variety of predictive imputation methods.\n",
    "\n",
    "Challenge: Now that we have filled those null values in with zeros, there are only two columns in the data set that still have null values: trany and drive. Use what you have learned in this section to investigate and potentially fill in the remaining null values.\n",
    "\n",
    "\n",
    "\n",
    "# Incorrect Values\n",
    "\n",
    "In addition to null values, we also want to try to identify any values that seem incorrect. For example, in the previous section, we learned that a vehicle without cylinders should not have displacement and vice versa. Let's check to see if there are any cases that violate these rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>trany</th>\n",
       "      <th>drive</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21506</th>\n",
       "      <td>1986</td>\n",
       "      <td>Mazda</td>\n",
       "      <td>RX-7</td>\n",
       "      <td>Manual 5-spd</td>\n",
       "      <td>Rear-Wheel Drive</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       year   make model         trany             drive fuelType  cylinders  \\\n",
       "21506  1986  Mazda  RX-7  Manual 5-spd  Rear-Wheel Drive  Regular        0.0   \n",
       "\n",
       "       displ  \n",
       "21506    1.3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data[(data['cylinders']==0) & (data['displ']!=0)]\n",
    "test[['year', 'make', 'model', 'trany', 'drive','fuelType','cylinders', 'displ']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have identified a vehicle with a regular gasoline engine that reportedly does not have any cylinders but does have a value for displacement. The way we would correct this would be to either perform some domain research or ask a domain expert to find out how many actual cylinders this vehicle had. Alternatively, you can also try to look at similar vehicles in the data set and determine the most likely value for this field.\n",
    "\n",
    "Suppose that using one of the aforementioned methods, we found out that this vehicle actually has a 4 cylinder engine. Once we have this information, we can use the loc method to update that specific value in the data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data['cylinders']==0) & (data['displ']!=0), 'cylinders'] = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Challenge: Try to find other values that might be incorrect in the data set based on what you know about automobiles and correct them.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Low Variance Columns\n",
    "\n",
    "When analyzing data, we want the fields we are working with to be informative, and we will want to strip away any columns that don't have a lot of value to us. One easy way to do this is to identify columns that have low variance, where the majority of the values in the column are the same. Since there is not a lot of variability in these columns, they have the potential to not be as informative as columns that have a variety of different values in them.\n",
    "\n",
    "Let's try to identify columns where at least 90% of the values are the same so that we can remove them from our data set. To do this, we are going to create an empty list called low_variance that will eventually contain the names of columns that fit our criteria. We will then write a for loop that will take the minimum and the 90th percentile value for all the numeric columns in our data set (identified via the _get_numeric_data method). If the 90th percentile and the minimum are equal to each other, that means that at least 90% of the values in that column are the same and we will append that column name to our low_variance list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['barrelsA08', 'charge120', 'charge240', 'cityA08', 'cityA08U', 'cityCD', 'cityE', 'cityUF', 'co2A', 'co2TailpipeAGpm', 'combA08', 'combA08U', 'combE', 'combinedCD', 'combinedUF', 'fuelCostA08', 'ghgScoreA', 'highwayA08', 'highwayA08U', 'highwayCD', 'highwayE', 'highwayUF', 'phevBlended', 'range', 'rangeCity', 'rangeCityA', 'rangeHwy', 'rangeHwyA', 'UCityA', 'UHighwayA', 'charge240b', 'phevCity', 'phevHwy', 'phevComb']\n"
     ]
    }
   ],
   "source": [
    "low_variance = []\n",
    "\n",
    "for col in data._get_numeric_data():\n",
    "    minimum = min(data[col])\n",
    "    ninety_perc = np.percentile(data[col], 90)\n",
    "    if ninety_perc == minimum:\n",
    "        low_variance.append(col)\n",
    "\n",
    "print(low_variance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returned 34 columns that we could potentially eliminate due to not having high enough variability to be informative. Of course, before we do this, we should check the values that do exist in these fields to confirm that they are not very informative. Once they have been checked, we can use the the drop method like we did earlier in this lesson to remove those columns from our data frame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(low_variance, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extreme Values and Outliers\n",
    "\n",
    "Now that we have removed low variance columns, we should look for outliers, or extreme values, in the columns that remain. These outliers can influence our aggregations when we are analyzing data later, so we want to make sure we address them during our data cleaning stage.\n",
    "\n",
    "A common method for identifying outliers is one that leverages the interquartile range (IQR). Once the IQR is calculated, it is multiplied by a constant (typically 1.5) and lower and upper bounds are established at:\n",
    "\n",
    "    25th Percentile - (IQR x 1.5)\n",
    "    75th Percentile + (IQR x 1.5)\n",
    "\n",
    "Any values outside this range are potential outliers and should be investigated.\n",
    "\n",
    "Let's look at how we would do this for our data set using Python. We will use the Pandas describe function to easily calculate the 25th and 75th percentiles for every column and transpose the results so that we can easily reference the values in calculating the interquartile ranges.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>displ</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>barrels08</th>\n",
       "      <th>city08</th>\n",
       "      <th>highway08</th>\n",
       "      <th>comb08</th>\n",
       "      <th>co2TailpipeGpm</th>\n",
       "      <th>fuelCost08</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36958.000000</td>\n",
       "      <td>36958.000000</td>\n",
       "      <td>36958.000000</td>\n",
       "      <td>36958.000000</td>\n",
       "      <td>36958.000000</td>\n",
       "      <td>36958.000000</td>\n",
       "      <td>36958.000000</td>\n",
       "      <td>36958.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.313572</td>\n",
       "      <td>5.728773</td>\n",
       "      <td>17.518871</td>\n",
       "      <td>17.950538</td>\n",
       "      <td>24.134017</td>\n",
       "      <td>20.211267</td>\n",
       "      <td>472.831339</td>\n",
       "      <td>1882.593755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.371037</td>\n",
       "      <td>1.781388</td>\n",
       "      <td>4.565909</td>\n",
       "      <td>6.705373</td>\n",
       "      <td>6.990806</td>\n",
       "      <td>6.661346</td>\n",
       "      <td>121.889046</td>\n",
       "      <td>510.085993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>550.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.200000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>14.330870</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>387.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>17.347895</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>467.736842</td>\n",
       "      <td>1850.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>20.600625</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>555.437500</td>\n",
       "      <td>2200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.400000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>47.087143</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>1269.571429</td>\n",
       "      <td>5800.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              displ     cylinders     barrels08        city08     highway08  \\\n",
       "count  36958.000000  36958.000000  36958.000000  36958.000000  36958.000000   \n",
       "mean       3.313572      5.728773     17.518871     17.950538     24.134017   \n",
       "std        1.371037      1.781388      4.565909      6.705373      6.990806   \n",
       "min        0.000000      0.000000      0.060000      6.000000      9.000000   \n",
       "25%        2.200000      4.000000     14.330870     15.000000     20.000000   \n",
       "50%        3.000000      6.000000     17.347895     17.000000     24.000000   \n",
       "75%        4.300000      6.000000     20.600625     20.000000     27.000000   \n",
       "max        8.400000     16.000000     47.087143    138.000000    111.000000   \n",
       "\n",
       "             comb08  co2TailpipeGpm    fuelCost08  \n",
       "count  36958.000000    36958.000000  36958.000000  \n",
       "mean      20.211267      472.831339   1882.593755  \n",
       "std        6.661346      121.889046    510.085993  \n",
       "min        7.000000        0.000000    550.000000  \n",
       "25%       16.000000      387.000000   1500.000000  \n",
       "50%       19.000000      467.736842   1850.000000  \n",
       "75%       23.000000      555.437500   2200.000000  \n",
       "max      124.000000     1269.571429   5800.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>IQR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>displ</th>\n",
       "      <td>36958.0</td>\n",
       "      <td>3.313572</td>\n",
       "      <td>1.371037</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.20000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>2.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cylinders</th>\n",
       "      <td>36958.0</td>\n",
       "      <td>5.728773</td>\n",
       "      <td>1.781388</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>barrels08</th>\n",
       "      <td>36958.0</td>\n",
       "      <td>17.518871</td>\n",
       "      <td>4.565909</td>\n",
       "      <td>0.06</td>\n",
       "      <td>14.33087</td>\n",
       "      <td>17.347895</td>\n",
       "      <td>20.600625</td>\n",
       "      <td>47.087143</td>\n",
       "      <td>6.269755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city08</th>\n",
       "      <td>36958.0</td>\n",
       "      <td>17.950538</td>\n",
       "      <td>6.705373</td>\n",
       "      <td>6.00</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>highway08</th>\n",
       "      <td>36958.0</td>\n",
       "      <td>24.134017</td>\n",
       "      <td>6.990806</td>\n",
       "      <td>9.00</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comb08</th>\n",
       "      <td>36958.0</td>\n",
       "      <td>20.211267</td>\n",
       "      <td>6.661346</td>\n",
       "      <td>7.00</td>\n",
       "      <td>16.00000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>co2TailpipeGpm</th>\n",
       "      <td>36958.0</td>\n",
       "      <td>472.831339</td>\n",
       "      <td>121.889046</td>\n",
       "      <td>0.00</td>\n",
       "      <td>387.00000</td>\n",
       "      <td>467.736842</td>\n",
       "      <td>555.437500</td>\n",
       "      <td>1269.571429</td>\n",
       "      <td>168.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuelCost08</th>\n",
       "      <td>36958.0</td>\n",
       "      <td>1882.593755</td>\n",
       "      <td>510.085993</td>\n",
       "      <td>550.00</td>\n",
       "      <td>1500.00000</td>\n",
       "      <td>1850.000000</td>\n",
       "      <td>2200.000000</td>\n",
       "      <td>5800.000000</td>\n",
       "      <td>700.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count         mean         std     min         25%  \\\n",
       "displ           36958.0     3.313572    1.371037    0.00     2.20000   \n",
       "cylinders       36958.0     5.728773    1.781388    0.00     4.00000   \n",
       "barrels08       36958.0    17.518871    4.565909    0.06    14.33087   \n",
       "city08          36958.0    17.950538    6.705373    6.00    15.00000   \n",
       "highway08       36958.0    24.134017    6.990806    9.00    20.00000   \n",
       "comb08          36958.0    20.211267    6.661346    7.00    16.00000   \n",
       "co2TailpipeGpm  36958.0   472.831339  121.889046    0.00   387.00000   \n",
       "fuelCost08      36958.0  1882.593755  510.085993  550.00  1500.00000   \n",
       "\n",
       "                        50%          75%          max         IQR  \n",
       "displ              3.000000     4.300000     8.400000    2.100000  \n",
       "cylinders          6.000000     6.000000    16.000000    2.000000  \n",
       "barrels08         17.347895    20.600625    47.087143    6.269755  \n",
       "city08            17.000000    20.000000   138.000000    5.000000  \n",
       "highway08         24.000000    27.000000   111.000000    7.000000  \n",
       "comb08            19.000000    23.000000   124.000000    7.000000  \n",
       "co2TailpipeGpm   467.736842   555.437500  1269.571429  168.437500  \n",
       "fuelCost08      1850.000000  2200.000000  5800.000000  700.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = data.describe().transpose()\n",
    "stats['IQR'] = stats['75%'] - stats['25%']\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then create an empty data frame called outliers with the same columns as our data set. Finally, we will loop through each column in the data calculating the lower and upper bounds, retrieving records where the value for that column falls outside the bounds we established, and appending those results to our outlier data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['displ', 'cylinders', 'barrels08', 'city08', 'highway08', 'comb08',\n",
       "       'co2TailpipeGpm', 'fuelCost08'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>barrels08</th>\n",
       "      <th>city08</th>\n",
       "      <th>city08U</th>\n",
       "      <th>co2</th>\n",
       "      <th>co2TailpipeGpm</th>\n",
       "      <th>comb08</th>\n",
       "      <th>comb08U</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displ</th>\n",
       "      <th>drive</th>\n",
       "      <th>...</th>\n",
       "      <th>pv4</th>\n",
       "      <th>trany</th>\n",
       "      <th>UCity</th>\n",
       "      <th>UHighway</th>\n",
       "      <th>VClass</th>\n",
       "      <th>year</th>\n",
       "      <th>youSaveSpend</th>\n",
       "      <th>createdOn</th>\n",
       "      <th>modifiedOn</th>\n",
       "      <th>Outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>32.961</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>888.7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Rear-Wheel Drive</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Automatic 3-spd</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Vans</td>\n",
       "      <td>1985</td>\n",
       "      <td>-10000</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>barrels08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>32.961</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>888.7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>Rear-Wheel Drive</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Automatic 3-spd</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Vans</td>\n",
       "      <td>1985</td>\n",
       "      <td>-10000</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>barrels08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>32.961</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>888.7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>Rear-Wheel Drive</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Automatic 3-spd</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Vans</td>\n",
       "      <td>1985</td>\n",
       "      <td>-10000</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>barrels08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>32.961</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>888.7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Rear-Wheel Drive</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Automatic 3-spd</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Vans</td>\n",
       "      <td>1985</td>\n",
       "      <td>-10000</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>barrels08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>32.961</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>888.7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>Rear-Wheel Drive</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Automatic 4-spd</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Standard Pickup Trucks</td>\n",
       "      <td>1993</td>\n",
       "      <td>-10000</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>Tue Jan 01 00:00:00 EST 2013</td>\n",
       "      <td>barrels08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     barrels08 city08  city08U co2  co2TailpipeGpm comb08  comb08U  cylinders  \\\n",
       "47      32.961      9      0.0  -1           888.7     10      0.0        8.0   \n",
       "58      32.961     10      0.0  -1           888.7     10      0.0        8.0   \n",
       "69      32.961     10      0.0  -1           888.7     10      0.0        8.0   \n",
       "80      32.961      9      0.0  -1           888.7     10      0.0        8.0   \n",
       "275     32.961      9      0.0  -1           888.7     10      0.0        8.0   \n",
       "\n",
       "     displ             drive  ... pv4            trany UCity UHighway  \\\n",
       "47     5.9  Rear-Wheel Drive  ...   0  Automatic 3-spd  11.0     15.0   \n",
       "58     5.2  Rear-Wheel Drive  ...   0  Automatic 3-spd  12.0     15.0   \n",
       "69     5.2  Rear-Wheel Drive  ...   0  Automatic 3-spd  12.0     15.0   \n",
       "80     5.9  Rear-Wheel Drive  ...   0  Automatic 3-spd  11.0     14.0   \n",
       "275    7.4  Rear-Wheel Drive  ...   0  Automatic 4-spd  11.0     16.0   \n",
       "\n",
       "                     VClass  year youSaveSpend                     createdOn  \\\n",
       "47                     Vans  1985       -10000  Tue Jan 01 00:00:00 EST 2013   \n",
       "58                     Vans  1985       -10000  Tue Jan 01 00:00:00 EST 2013   \n",
       "69                     Vans  1985       -10000  Tue Jan 01 00:00:00 EST 2013   \n",
       "80                     Vans  1985       -10000  Tue Jan 01 00:00:00 EST 2013   \n",
       "275  Standard Pickup Trucks  1993       -10000  Tue Jan 01 00:00:00 EST 2013   \n",
       "\n",
       "                       modifiedOn    Outlier  \n",
       "47   Tue Jan 01 00:00:00 EST 2013  barrels08  \n",
       "58   Tue Jan 01 00:00:00 EST 2013  barrels08  \n",
       "69   Tue Jan 01 00:00:00 EST 2013  barrels08  \n",
       "80   Tue Jan 01 00:00:00 EST 2013  barrels08  \n",
       "275  Tue Jan 01 00:00:00 EST 2013  barrels08  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers = pd.DataFrame(columns=data.columns)\n",
    "\n",
    "for col in stats.index:\n",
    "    iqr = stats.at[col,'IQR']\n",
    "    cutoff = iqr * 1.5\n",
    "    lower = stats.at[col,'25%'] - cutoff\n",
    "    upper = stats.at[col,'75%'] + cutoff\n",
    "    results = data[(data[col] < lower) | \n",
    "                   (data[col] > upper)].copy()\n",
    "    results['Outlier'] = col\n",
    "    outliers = outliers.append(results)\n",
    "    \n",
    "\n",
    "outliers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our outliers data frame should now be populated with records that you can investigate further and determine whether they should be kept in the data or dropped. The Outlier column we added before appending the results for the column to the outliers data frame will let you know what column in each record contained the outlier. If you find that this method is returning too many results, you can be more stringent with your cutoff criteria (e.g. increasing the constant by which you multiply the IQR to 3 instead of 1.5).\n",
    "Data Type Correction\n",
    "\n",
    "One common problem that is often overlooked is incorrect data types. This typically occurs when there is a numeric variable that should actually be represented as a categorical variable. The way to check the data type of each column in Pandas is by using the dtypes method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "barrels08         float64\n",
       "city08              int64\n",
       "city08U           float64\n",
       "co2                 int64\n",
       "co2TailpipeGpm    float64\n",
       "comb08              int64\n",
       "comb08U           float64\n",
       "cylinders         float64\n",
       "displ             float64\n",
       "drive              object\n",
       "engId               int64\n",
       "feScore             int64\n",
       "fuelCost08          int64\n",
       "fuelType           object\n",
       "fuelType1          object\n",
       "ghgScore            int64\n",
       "highway08           int64\n",
       "highway08U        float64\n",
       "hlv                 int64\n",
       "hpv                 int64\n",
       "id                  int64\n",
       "lv2                 int64\n",
       "lv4                 int64\n",
       "make               object\n",
       "model              object\n",
       "mpgData            object\n",
       "pv2                 int64\n",
       "pv4                 int64\n",
       "trany              object\n",
       "UCity             float64\n",
       "UHighway          float64\n",
       "VClass             object\n",
       "year                int64\n",
       "youSaveSpend        int64\n",
       "createdOn          object\n",
       "modifiedOn         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas currently has the year column stored as integers, but what if we wanted the year to be stored as a categorical variable (object) instead? We could easily change that data type using the astype method and then check that it changed using the dtypes method again just on that field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['year'] = data['year'].astype('object')\n",
    "data['year'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can apply this technique to any column whose data type you would like to change.\n",
    "\n",
    "\n",
    "\n",
    "# Cleaning Text and Removing Special Characters\n",
    "\n",
    "The presence of special characters in our fields has the potential to make analyzing our data challenging. Imagine not being able to perform calculations on a numeric field because it was currently represented as an object data type due to the fact that it had a dollar sign ($) in it. Similarly, imagine having a categorical field where you could not group records that belong in the same group together because in one field you are grouping by, terms that refer to the same thing are sometimes hyphenated. In cases like this, it is necessary to remove special characters so that we can properly analyze the data.\n",
    "\n",
    "In our vehicles data set, the trany field has several special characters (parentheses, hyphens, etc.). We can take a look at the unique values in this column by using the set function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{nan, 'Automatic 6-spd', 'Auto(AM-S8)', 'Auto(AM6)', 'Automatic (AV)', 'Automatic 9-spd', 'Auto(AV-S7)', 'Manual 5 spd', 'Auto(AM-S9)', 'Manual 3-spd', 'Automatic 8-spd', 'Auto(AV-S8)', 'Automatic (variable gear ratios)', 'Automatic (S4)', 'Auto(AV-S6)', 'Automatic 5-spd', 'Auto(AM-S6)', 'Automatic (S9)', 'Auto(L3)', 'Auto (AV-S6)', 'Auto (AV-S8)', 'Auto(A1)', 'Automatic 3-spd', 'Automatic 7-spd', 'Manual 4-spd Doubled', 'Automatic (AM5)', 'Automatic (S7)', 'Manual 5-spd', 'Automatic (S5)', 'Auto (AV)', 'Automatic 4-spd', 'Automatic (S8)', 'Manual(M7)', 'Auto(AM5)', 'Manual 4-spd', 'Auto(AM-S7)', 'Automatic 6spd', 'Auto(AM8)', 'Automatic (A6)', 'Automatic (A1)', 'Auto(L4)', 'Manual 6-spd', 'Automatic (AV-S6)', 'Automatic (S6)', 'Auto(AM7)', 'Manual 7-spd', 'Automatic (AM6)'}\n"
     ]
    }
   ],
   "source": [
    "print(set(data['trany']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are instances that refer to the same thing, but would not get grouped together due to special characters (e.g. Automatic 6-spd and Automatic 6spd). So let's remove all hyphens from this column with the help of the str.replace method and then print unique values again to ensure they were removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{nan, 'Auto(AVS6)', 'Auto (AVS8)', 'Manual 6spd', 'Manual 3spd', 'Auto(AM6)', 'Automatic 4spd', 'Automatic 5spd', 'Automatic (AV)', 'Manual 4spd Doubled', 'Manual 4spd', 'Automatic 7spd', 'Manual 5 spd', 'Auto(AVS8)', 'Automatic (variable gear ratios)', 'Automatic (S4)', 'Auto(AMS6)', 'Automatic (S9)', 'Auto(L3)', 'Auto(AMS8)', 'Automatic 9spd', 'Auto(A1)', 'Automatic 3spd', 'Automatic (AM5)', 'Automatic (S7)', 'Automatic 8spd', 'Automatic (S5)', 'Auto (AV)', 'Auto(AMS9)', 'Automatic (S8)', 'Manual(M7)', 'Manual 7spd', 'Auto(AM5)', 'Automatic 6spd', 'Auto(AM8)', 'Automatic (A6)', 'Automatic (A1)', 'Manual 5spd', 'Automatic (AVS6)', 'Auto(L4)', 'Auto (AVS6)', 'Automatic (S6)', 'Auto(AM7)', 'Auto(AMS7)', 'Automatic (AM6)', 'Auto(AVS7)'}\n"
     ]
    }
   ],
   "source": [
    "data['trany'] = data['trany'].str.replace('-', '')\n",
    "print(set(data['trany']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will also notice that in some cases Automatic is abbreviated to Auto and in other cases it is spelled out. We can make that more consistent by using the same technique. While we are at it, let's also attempt to remove parentheses and make spacing more consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{nan, 'Auto 3spd', 'Manual 6spd', 'Manual 3spd', 'Manual 4spd Doubled', 'Auto AM7', 'Manual 4spd', 'Auto 9spd', 'Manual 5 spd', 'Auto AVS7', 'Auto 4spd', 'Auto 7spd', 'Auto S7', 'Auto 8spd', 'Auto S9', 'Auto AVS6', 'Auto AV', 'Auto AMS8', 'Auto L4', 'Auto A6', 'Auto S8', 'Auto variable gear ratios', 'Auto L3', 'Auto 5spd', 'Auto S4', 'Manual M7', 'Auto AM6', 'Auto AM8', 'Auto AMS7', 'Auto AVS8', 'Auto AM5', 'Auto S5', 'Auto 6spd', 'Auto AMS6', 'Manual 5spd', 'Auto S6', 'Auto AMS9', 'Auto A1', 'Manual 7spd'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-b7c50a551c79>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['trany'] = data['trany'].str.replace('Auto\\(', 'Auto ')\n",
      "<ipython-input-19-b7c50a551c79>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['trany'] = data['trany'].str.replace('Manual\\(', 'Manual ')\n",
      "<ipython-input-19-b7c50a551c79>:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['trany'] = data['trany'].str.replace('\\(', '')\n",
      "<ipython-input-19-b7c50a551c79>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['trany'] = data['trany'].str.replace('\\)', '')\n"
     ]
    }
   ],
   "source": [
    "data['trany'] = data['trany'].str.replace('Automatic', 'Auto')\n",
    "data['trany'] = data['trany'].str.replace('Auto\\(', 'Auto ')\n",
    "data['trany'] = data['trany'].str.replace('Manual\\(', 'Manual ')\n",
    "data['trany'] = data['trany'].str.replace('\\(', '')\n",
    "data['trany'] = data['trany'].str.replace('\\)', '')\n",
    "print(set(data['trany']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we now have no special characters, consistent naming, and proper spacing. We started out with 47 unique values in this column, and using this technique, we were able to reduce the number of unique values to 39.\n",
    "\n",
    "\n",
    "\n",
    "# Finding and Removing Duplicates\n",
    "\n",
    "The final topic we are going to cover in this lesson is how to identify and remove duplicate rows (or rows that refer to the same entity) in our data. When trying to identify duplicates, we will use the columns (or attributes) of the data to help us determine what entities are similar enough to be considered the same entity. We want to start with all the columns we currently have available to us and work our way toward a lesser number of attributes in an intuitive fashion. In this process, the act of dropping duplicated records is easy, but identifying the correct attributes for comparison and which records to drop is sometimes quite challenging.\n",
    "\n",
    "The first thing we will do is attempt to drop any duplicate records, considering all the columns we currently have in the data set. Pandas provides us with the ability to do that via the drop_duplicates method. We will use the len method to calculate the number of rows in the data set both before and after removing duplicates and then print the number of rows dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate records dropped:  0\n"
     ]
    }
   ],
   "source": [
    "before = len(data)\n",
    "data = data.drop_duplicates()\n",
    "after = len(data)\n",
    "print('Number of duplicate records dropped: ', str(before - after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that there were no records that matched exactly across all columns. However, if we reduce the number of columns in our data that we are interested in, we can try again and have a higher likelihood of finding duplicate records. In the example below, we will select a subset of columns, remove all other columns, and then use the drop_duplicates method to drop any duplicate records based on the remaining columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate records dropped:  885\n"
     ]
    }
   ],
   "source": [
    "select_columns = ['make', 'model', 'year', 'displ', 'cylinders', \n",
    "                  'trany', 'drive', 'VClass','fuelType','barrels08', \n",
    "                  'city08', 'highway08', 'comb08', 'co2TailpipeGpm', 'fuelCost08']\n",
    "\n",
    "data = data[select_columns].drop_duplicates()\n",
    "after = len(data)\n",
    "print('Number of duplicate records dropped: ', str(before - after))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the reduced number of columns, we were able to identify and drop 885 duplicate records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
